{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMcaOSCn5sqfBE0Ip6KkZgk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/genai-research-and-practice/blob/main/generative-ai-with-langchain/02_customer_service.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "7qUr7aj3kHY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain openai tiktoken accelerate cohere --quiet"
      ],
      "metadata": {
        "id": "H0RkmCtukISE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import list_models\n",
        "from langchain import HuggingFaceHub\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "from langchain.llms import VertexAI\n",
        "from langchain import PromptTemplate, LLMChain"
      ],
      "metadata": {
        "id": "7yMgVV98kSUm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "ZndCq9GXlSt5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ['HUGGINGFACEHUB_API_TOKEN'] = ''"
      ],
      "metadata": {
        "id": "ekNb7WTAr4oJ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Sentiment Model"
      ],
      "metadata": {
        "id": "dqYQ9ncLl4F2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def list_most_popular(task: str):\n",
        "  for rank, model in enumerate(list_models(filter=task, sort=\"downloads\", direction=-1)):\n",
        "    if rank == 5:\n",
        "      break\n",
        "    print(f\"{model.id}, {model.downloads}\\n\")\n",
        "\n",
        "# We can list the 5 most downloaded models on Hugging Face Hub for text classification\n",
        "list_most_popular(\"text-classification\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24OZa707lHoa",
        "outputId": "66927d43-6c57-4874-a6dc-8c2091c672a1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardiffnlp/twitter-roberta-base-sentiment-latest, 47328119\n",
            "\n",
            "lxyuan/distilbert-base-multilingual-cased-sentiments-student, 10379763\n",
            "\n",
            "cardiffnlp/twitter-roberta-base-irony, 10217088\n",
            "\n",
            "mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis, 10034515\n",
            "\n",
            "SamLowe/roberta-base-go_emotions, 9812542\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let’s see what our sentiment model has to say\n",
        "customer_email = \"\"\"\n",
        "I hope this email finds you amidst an aura of understanding, despite the tangled mess of emotions swirling within me as I write to you. I am writing to pour my heart out about the recent unfortunate experience I had with one of your coffee machines that arrived ominously broken, evoking a profound sense of disbelief and despair.\n",
        "To set the scene, let me paint you a picture of the moment I anxiously unwrapped the box containing my highly anticipated coffee machine. The blatant excitement coursing through my veins could rival the vigorous flow of coffee through its finest espresso artistry. However, what I discovered within broke not only my spirit but also any semblance of confidence I had placed in your esteemed brand.\n",
        "Imagine, if you can, the utter shock and disbelief that took hold of me as I laid eyes on a disheveled and mangled coffee machine. Its once elegant exterior was marred by the scars of travel, resembling a war-torn soldier who had fought valiantly on the fields of some espresso battlefield. This heartbreaking display of negligence shattered my dreams of indulging in daily coffee perfection, leaving me emotionally distraught and inconsolable\n",
        "\"\"\"\n",
        "\n",
        "sentiment_model = pipeline(\n",
        "    task=\"sentiment-analysis\",\n",
        "    model=\"cardiffnlp/twitter-roberta-base-sentiment\"\n",
        ")"
      ],
      "metadata": {
        "id": "umwafu3_lPo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentiment_model(customer_email))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gb12a4vbmP0r",
        "outputId": "4f6bc31e-86f3-4fa4-c866-8b3a2196321a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'LABEL_0', 'score': 0.5824514031410217}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentiment_model(\"I am so angry and sad, I want to kill myself!\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvcERWivmUkJ",
        "outputId": "1c532ba4-8b33-407c-bc8e-efdfbc44e4b2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'LABEL_0', 'score': 0.9788626432418823}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentiment_model(\"I am elated, I am so happy, this is the best thing that ever happened to me!\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-guTy9jmbX5",
        "outputId": "9fff0223-18f3-4297-f8d0-45bbb4e1ebd4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'LABEL_2', 'score': 0.9926880598068237}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentiment_model(\"I don't care. I guess it's ok, or not, I couldn't care one way or the other\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JJsC4LMmeQp",
        "outputId": "dd4cbcc2-6f5b-46f8-8db4-fd5bbc217c41"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'LABEL_1', 'score': 0.5958544611930847}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Summarization model"
      ],
      "metadata": {
        "id": "SC5Z0K0NmyF6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let’s execute the summarization model remotely on a server\n",
        "summarizer = HuggingFaceHub(\n",
        "    repo_id=\"facebook/bart-large-cnn\",\n",
        "    model_kwargs={\"temperature\": 0, \"max_length\": 180}\n",
        ")"
      ],
      "metadata": {
        "id": "xgCIQJFymhz3"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize(llm, text)-> str:\n",
        "  return llm(f\"Summarize this: {text}\")"
      ],
      "metadata": {
        "id": "HurtnTDLnH_H"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summarize(summarizer, customer_email)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "aJl0AQvysg2G",
        "outputId": "156482ad-41dc-4c76-84c7-6465c25240d0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"I am writing to pour my heart out about the recent unfortunate experience I had with one of your coffee machines that arrived ominously broken,\" writes the customer. \"Imagine, if you can, the utter shock and disbelief that took hold of me as I laid eyes on a disheveled and mangled coffee machine,\" he writes. \"This heartbreaking display of negligence shattered my dreams of indulging in daily coffee perfection,\" he adds.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Customer Service Assistance"
      ],
      "metadata": {
        "id": "cWRZP9y4s7-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"\n",
        "Given this text, decide what is the issue the customer is concerned about. Valid categories are these:\n",
        "* product issues\n",
        "* delivery problems\n",
        "* missing or late orders\n",
        "* wrong product\n",
        "* cancellation request\n",
        "* refund or exchange\n",
        "* bad support experience\n",
        "* no clear reason to be upset\n",
        "\n",
        "Text: {email}\n",
        "Category:\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"email\"])\n",
        "llm = VertexAI()\n",
        "llm_chain = LLMChain(prompt=prompt, llm=llm, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "Pw7mzQpHshVw",
        "outputId": "95e93479-7be0-4ad3-d290-1b6d625f29bc"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValidationError",
          "evalue": "1 validation error for VertexAI\n__root__\n  Unable to find your project. Please provide a project ID by:\n- Passing a constructor argument\n- Using vertexai.init()\n- Setting project using 'gcloud config set project my-project'\n- Setting a GCP environment variable\n- To create a Google Cloud project, please follow guidance at https://developers.google.com/workspace/guides/create-project (type=value_error)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-5a906540c11b>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPromptTemplate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_variables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"email\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mllm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVertexAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mllm_chain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLLMChain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarn_if_direct_instance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m                         \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                 obj.__init__ = functools.wraps(obj.__init__)(  # type: ignore[misc]\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/load/serializable.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lc_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pydantic/main.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValidationError\u001b[0m: 1 validation error for VertexAI\n__root__\n  Unable to find your project. Please provide a project ID by:\n- Passing a constructor argument\n- Using vertexai.init()\n- Setting project using 'gcloud config set project my-project'\n- Setting a GCP environment variable\n- To create a Google Cloud project, please follow guidance at https://developers.google.com/workspace/guides/create-project (type=value_error)"
          ]
        }
      ]
    }
  ]
}