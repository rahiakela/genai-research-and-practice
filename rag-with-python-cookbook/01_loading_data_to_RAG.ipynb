{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/genai-research-and-practice/blob/main/rag-with-python-cookbook/01_loading_data_to_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05e3baf3",
      "metadata": {
        "id": "05e3baf3"
      },
      "source": [
        "##Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "This notebook uses the following Python packages:\n",
        "\n",
        "- `python-docx` (Word document reading)\n",
        "- `unstructured` (document partitioning)\n",
        "- `python-magic-bin` (file type detection)\n",
        "- `pandas` (data manipulation)\n",
        "- `PyPDF2` (PDF reading)\n",
        "- `pillow` (image processing)\n",
        "- `openpyxl` (Excel file reading)\n",
        "- `pdf2image` (PDF to image conversion)\n",
        "- `pytesseract` (OCR)\n",
        "- `openai` (OpenAI API)\n",
        "- `python-dotenv` (environment variable management)\n",
        "- `sqlalchemy` (database connection)\n",
        "- `psycopg2-binary` (PostgreSQL driver)\n",
        "- `moviepy` (video processing)\n",
        "- `pdfminer.six` (PDF text extraction)\n",
        "- `pi-heif` (HEIF image support)\n",
        "- `unstructured-inference` (document inference)\n",
        "\n",
        "Some helper functions may require additional dependencies. Install these packages using pip before running the notebook."
      ],
      "metadata": {
        "id": "VLdsQWz6XKow"
      },
      "id": "VLdsQWz6XKow"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f87a12ba",
      "metadata": {
        "id": "f87a12ba"
      },
      "outputs": [],
      "source": [
        "!pip install python-docx==1.1.2\n",
        "!pip install unstructured==0.17.2\n",
        "# !pip install python-magic-bin==0.4.14\n",
        "!pip install pandas==2.2.3\n",
        "!pip install PyPDF2==3.0.1\n",
        "!pip install pillow==11.2.1\n",
        "!pip install openpyxl==3.1.5\n",
        "# !pip install pdf2image==1.17.0\n",
        "# !pip install pytesseract==0.3.13\n",
        "# !pip install openai==1.82.1\n",
        "# !pip install python-dotenv==1.1.0\n",
        "# !pip install sqlalchemy==2.0.41\n",
        "# !pip install psycopg2-binary==2.9.10\n",
        "# !pip install moviepy==2.2.1\n",
        "# !pip install pdfminer.six==20250506\n",
        "# !pip install pi-heif==0.22.0\n",
        "# !pip install unstructured-inference==1.0.2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "528931c5",
      "metadata": {
        "id": "528931c5"
      },
      "source": [
        "## 1.1 Loading Word Files in Python"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "add2c2f2",
      "metadata": {
        "id": "add2c2f2"
      },
      "source": [
        "**Option 1**: load word files using the python_docx library"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/polzerdo55862/RAG-with-Python-Cookbook/raw/main/datasets/word_files/2023_Jan_7_Feature_Engineering_Techniques.docx"
      ],
      "metadata": {
        "id": "kL-uPfASXqxx"
      },
      "id": "kL-uPfASXqxx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97da2421",
      "metadata": {
        "id": "97da2421"
      },
      "outputs": [],
      "source": [
        "# tag::python_docx[]\n",
        "import os\n",
        "from docx import Document\n",
        "\n",
        "file_path = \"2023_Jan_7_Feature_Engineering_Techniques.docx\"\n",
        "\n",
        "doc = Document(file_path)\n",
        "\n",
        "text = []\n",
        "for paragraph in doc.paragraphs:\n",
        "    text.append(paragraph.text)\n",
        "\n",
        "full_text = \"\\n\".join(text)\n",
        "# end::python_docx[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0e1c8e7",
      "metadata": {
        "id": "b0e1c8e7"
      },
      "outputs": [],
      "source": [
        "full_text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b20a45a7",
      "metadata": {
        "id": "b20a45a7"
      },
      "source": [
        "**Option 2**: load word files using the unstructured library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8bf7132",
      "metadata": {
        "id": "b8bf7132"
      },
      "outputs": [],
      "source": [
        "# tag::unstructured[]\n",
        "from unstructured.partition.docx import partition_docx\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "elements = partition_docx(filename=file_path)\n",
        "\n",
        "list_of_elements = []\n",
        "\n",
        "for element in elements:\n",
        "    element_dict = {\n",
        "        \"element_id\": element.id,\n",
        "        \"file_path\": file_path,\n",
        "        \"category\": element.category,  # e.g. \"Title\", \"NarrativeText\", \"ListItem\"\n",
        "        \"text\": element.text,\n",
        "        \"last_modified\": element.metadata.last_modified,\n",
        "    }\n",
        "\n",
        "    list_of_elements.append(element_dict)\n",
        "\n",
        "elements_df = pd.DataFrame(list_of_elements)\n",
        "# end::unstructured[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2292c546",
      "metadata": {
        "id": "2292c546",
        "outputId": "9dd70ddc-7c2f-4c54-d908-cffb82a80c9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         element_id  \\\n",
              "0  135f726911a68beceb56d92e2b9d10bc   \n",
              "1  f275447183f11b993f2a87d4b428299b   \n",
              "2  9dacd0881e31b366756a6cc20884f661   \n",
              "3  3bec63fc43107e87aae98bbaf5313196   \n",
              "4  b1b29811f875047fef0bab817d6325c5   \n",
              "\n",
              "                                        file_path           category  \\\n",
              "0  2023_Jan_7_Feature_Engineering_Techniques.docx              Title   \n",
              "1  2023_Jan_7_Feature_Engineering_Techniques.docx              Title   \n",
              "2  2023_Jan_7_Feature_Engineering_Techniques.docx      NarrativeText   \n",
              "3  2023_Jan_7_Feature_Engineering_Techniques.docx              Title   \n",
              "4  2023_Jan_7_Feature_Engineering_Techniques.docx  UncategorizedText   \n",
              "\n",
              "                                                text        last_modified  \n",
              "0  7 of the Most Used Feature Engineering Techniques  2025-06-30T10:28:28  \n",
              "1  Hands-on Feature Engineering with Scikit-Learn...  2025-06-30T10:28:28  \n",
              "2  7 of the most used Feature Engineering Techniq...  2025-06-30T10:28:28  \n",
              "3                                   Table of content  2025-06-30T10:28:28  \n",
              "4                                       Introduction  2025-06-30T10:28:28  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-153a9f9a-33cf-49cb-b55f-323c63876e52\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>element_id</th>\n",
              "      <th>file_path</th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "      <th>last_modified</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>135f726911a68beceb56d92e2b9d10bc</td>\n",
              "      <td>2023_Jan_7_Feature_Engineering_Techniques.docx</td>\n",
              "      <td>Title</td>\n",
              "      <td>7 of the Most Used Feature Engineering Techniques</td>\n",
              "      <td>2025-06-30T10:28:28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>f275447183f11b993f2a87d4b428299b</td>\n",
              "      <td>2023_Jan_7_Feature_Engineering_Techniques.docx</td>\n",
              "      <td>Title</td>\n",
              "      <td>Hands-on Feature Engineering with Scikit-Learn...</td>\n",
              "      <td>2025-06-30T10:28:28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9dacd0881e31b366756a6cc20884f661</td>\n",
              "      <td>2023_Jan_7_Feature_Engineering_Techniques.docx</td>\n",
              "      <td>NarrativeText</td>\n",
              "      <td>7 of the most used Feature Engineering Techniq...</td>\n",
              "      <td>2025-06-30T10:28:28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3bec63fc43107e87aae98bbaf5313196</td>\n",
              "      <td>2023_Jan_7_Feature_Engineering_Techniques.docx</td>\n",
              "      <td>Title</td>\n",
              "      <td>Table of content</td>\n",
              "      <td>2025-06-30T10:28:28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>b1b29811f875047fef0bab817d6325c5</td>\n",
              "      <td>2023_Jan_7_Feature_Engineering_Techniques.docx</td>\n",
              "      <td>UncategorizedText</td>\n",
              "      <td>Introduction</td>\n",
              "      <td>2025-06-30T10:28:28</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-153a9f9a-33cf-49cb-b55f-323c63876e52')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-153a9f9a-33cf-49cb-b55f-323c63876e52 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-153a9f9a-33cf-49cb-b55f-323c63876e52');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e88eec98-8d0c-4705-9061-2a6afa10289f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e88eec98-8d0c-4705-9061-2a6afa10289f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e88eec98-8d0c-4705-9061-2a6afa10289f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "elements_df",
              "summary": "{\n  \"name\": \"elements_df\",\n  \"rows\": 397,\n  \"fields\": [\n    {\n      \"column\": \"element_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 397,\n        \"samples\": [\n          \"6266c2ac53cd31187bdbff1b35ec37d3\",\n          \"ec95c657b6c3d68ab29860fb48ec9cb6\",\n          \"0fd64e96f7d9a2edb40e4a727e5f26ba\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"file_path\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"2023_Jan_7_Feature_Engineering_Techniques.docx\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"NarrativeText\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 383,\n        \"samples\": [\n          \"Let's say we have a series of apartments we want to sell and have the technical blueprints and thus the dimensions of the apartments available.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"last_modified\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"2025-06-30T10:28:28\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "elements_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b42caeb4",
      "metadata": {
        "id": "b42caeb4"
      },
      "source": [
        "## 1.2 Loading PDF Files"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/polzerdo55862/RAG-with-Python-Cookbook/raw/main/datasets/pdf_files/2023_Jan_7_Feature_Engineering_Techniques.pdf"
      ],
      "metadata": {
        "id": "SvtZG-p_bN92"
      },
      "id": "SvtZG-p_bN92",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "708ad118",
      "metadata": {
        "id": "708ad118"
      },
      "outputs": [],
      "source": [
        "# tag::load_pdf_using_PyPDF2[]\n",
        "import PyPDF2\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "file_path = \"2023_Jan_7_Feature_Engineering_Techniques.pdf\"\n",
        "\n",
        "with open(file_path, \"rb\") as file:\n",
        "    reader = PyPDF2.PdfReader(file)\n",
        "\n",
        "    # Initialize an empty string to store the extracted text\n",
        "    list_of_pages = []\n",
        "    page_counter = 1\n",
        "\n",
        "    for page in reader.pages:\n",
        "        page_dict = {\n",
        "            \"file_name\": reader.metadata.get(\"/Title\"),\n",
        "            \"producer\": reader.metadata.get(\"/Producer\"),\n",
        "            \"page_number\": page_counter,\n",
        "            \"text\": page.extract_text(),\n",
        "            \"images\": page.images,\n",
        "        }\n",
        "\n",
        "        list_of_pages.append(page_dict)\n",
        "\n",
        "        page_counter += 1\n",
        "# end::load_pdf_using_PyPDF2[]\n",
        "\n",
        "# Convert the list of pages to a pandas DataFrame\n",
        "pages_df = pd.DataFrame(list_of_pages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b449b9eb",
      "metadata": {
        "id": "b449b9eb",
        "outputId": "e19b7c4b-d2e1-4016-d47a-2d376b4d6ea7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                   file_name  \\\n",
              "0  2023_Jan_7_Feature_Engineering_Techniques   \n",
              "1  2023_Jan_7_Feature_Engineering_Techniques   \n",
              "2  2023_Jan_7_Feature_Engineering_Techniques   \n",
              "3  2023_Jan_7_Feature_Engineering_Techniques   \n",
              "4  2023_Jan_7_Feature_Engineering_Techniques   \n",
              "\n",
              "                             producer  page_number  \\\n",
              "0  Skia/PDF m131 Google Docs Renderer            1   \n",
              "1  Skia/PDF m131 Google Docs Renderer            2   \n",
              "2  Skia/PDF m131 Google Docs Renderer            3   \n",
              "3  Skia/PDF m131 Google Docs Renderer            4   \n",
              "4  Skia/PDF m131 Google Docs Renderer            5   \n",
              "\n",
              "                                                text  \\\n",
              "0  7\\nof\\nthe\\nMost\\nUsed\\nFeature\\nEngineering\\n...   \n",
              "1  3.2\\nBucketizing\\nusing\\nTensorflow\\n3.3\\nBuck...   \n",
              "2  A\\nstandard\\nMachine\\nLearning\\npipeline — Ins...   \n",
              "3  ●\\nI\\nn\\nthe\\nsupply\\nchain\\ncontext\\n,\\nevery...   \n",
              "4  Once\\nwe\\nhave\\nenough\\ndata\\nthat\\ndescribes\\...   \n",
              "\n",
              "                                 images  \n",
              "0     [File(name=X7.png, data: 2.2 kB)]  \n",
              "1                                    []  \n",
              "2  [File(name=X17.png, data: 692 Byte)]  \n",
              "3    [File(name=X20.png, data: 2.6 kB)]  \n",
              "4    [File(name=X26.png, data: 1.5 kB)]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8e2572d3-8850-4445-94f4-912df9cca4e8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>producer</th>\n",
              "      <th>page_number</th>\n",
              "      <th>text</th>\n",
              "      <th>images</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2023_Jan_7_Feature_Engineering_Techniques</td>\n",
              "      <td>Skia/PDF m131 Google Docs Renderer</td>\n",
              "      <td>1</td>\n",
              "      <td>7\\nof\\nthe\\nMost\\nUsed\\nFeature\\nEngineering\\n...</td>\n",
              "      <td>[File(name=X7.png, data: 2.2 kB)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2023_Jan_7_Feature_Engineering_Techniques</td>\n",
              "      <td>Skia/PDF m131 Google Docs Renderer</td>\n",
              "      <td>2</td>\n",
              "      <td>3.2\\nBucketizing\\nusing\\nTensorflow\\n3.3\\nBuck...</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2023_Jan_7_Feature_Engineering_Techniques</td>\n",
              "      <td>Skia/PDF m131 Google Docs Renderer</td>\n",
              "      <td>3</td>\n",
              "      <td>A\\nstandard\\nMachine\\nLearning\\npipeline — Ins...</td>\n",
              "      <td>[File(name=X17.png, data: 692 Byte)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2023_Jan_7_Feature_Engineering_Techniques</td>\n",
              "      <td>Skia/PDF m131 Google Docs Renderer</td>\n",
              "      <td>4</td>\n",
              "      <td>●\\nI\\nn\\nthe\\nsupply\\nchain\\ncontext\\n,\\nevery...</td>\n",
              "      <td>[File(name=X20.png, data: 2.6 kB)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2023_Jan_7_Feature_Engineering_Techniques</td>\n",
              "      <td>Skia/PDF m131 Google Docs Renderer</td>\n",
              "      <td>5</td>\n",
              "      <td>Once\\nwe\\nhave\\nenough\\ndata\\nthat\\ndescribes\\...</td>\n",
              "      <td>[File(name=X26.png, data: 1.5 kB)]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8e2572d3-8850-4445-94f4-912df9cca4e8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8e2572d3-8850-4445-94f4-912df9cca4e8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8e2572d3-8850-4445-94f4-912df9cca4e8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6494a0e8-ec72-4db0-8393-8a8de549e83d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6494a0e8-ec72-4db0-8393-8a8de549e83d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6494a0e8-ec72-4db0-8393-8a8de549e83d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "pages_df",
              "summary": "{\n  \"name\": \"pages_df\",\n  \"rows\": 56,\n  \"fields\": [\n    {\n      \"column\": \"file_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"2023_Jan_7_Feature_Engineering_Techniques\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"producer\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Skia/PDF m131 Google Docs Renderer\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"page_number\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16,\n        \"min\": 1,\n        \"max\": 56,\n        \"num_unique_values\": 56,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 56,\n        \"samples\": [\n          \"7\\nof\\nthe\\nMost\\nUsed\\nFeature\\nEngineering\\nTechniques\\nHands-on\\nFeature\\nEngineering\\nwith\\nScikit-Learn,\\nTensorflow,\\nPandas\\nand\\nScipy\\n7\\nof\\nthe\\nmost\\nused\\nFeature\\nEngineering\\nTechniques\\u200a\\u2014\\u200aImage\\nby\\nthe\\nauthor\\nTable\\nof\\ncontent\\nIntroduction\\n1.\\nEncoding\\n1.1\\nLabel\\nEncoding\\nusing\\nScikit-learn\\n1.2\\nOne-Hot\\nEncoding\\nusing\\nScikit-learn,\\nPandas\\nand\\nTensorflow\\n2.\\nFeature\\nHashing\\n2.1\\nFeature\\nHashing\\nusing\\nScikit-learn\\n3.\\nBinning\\n/\\nBucketizing\\n3.1\\nBucketizing\\nusing\\nPandas\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"images\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Display the first few rows of the DataFrame\n",
        "pages_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54b86d86",
      "metadata": {
        "id": "54b86d86"
      },
      "source": [
        "## 1.3 Loading and Handling CSV and Excel Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e77df492",
      "metadata": {
        "id": "e77df492"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/polzerdo55862/RAG-with-Python-Cookbook/raw/main/datasets/csv_files/census-income.xlsx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9b4a6c0",
      "metadata": {
        "id": "f9b4a6c0"
      },
      "outputs": [],
      "source": [
        "###########################################################################################################\n",
        "# Define the file path to the Word document\n",
        "###########################################################################################################\n",
        "# tag::create_additional_table_column[]\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "file_path = \"census-income.xlsx\"\n",
        "df_excel = pd.read_excel(io=file_path)\n",
        "\n",
        "\n",
        "def create_text_description_of_row(row):\n",
        "    row[\"text_description\"] = (\n",
        "        f\"\"\"The candidate {row['age']} years old is working in the\n",
        "            {row['workclass']} sector. The candidate was born in\n",
        "            {row['native-country']}, is {row['marital-status']}\n",
        "            and has a {row['relationship']} relationship.\n",
        "            The candidate has a {row['education']} degree\n",
        "            and is working as a {row['occupation']}.\n",
        "            The income of the candidate is {row['income']}.\"\"\"\n",
        "    )\n",
        "\n",
        "    return row\n",
        "\n",
        "\n",
        "# Apply the function create_text_description_of_row to each row of the data frame\n",
        "df_extended = df_excel.apply(create_text_description_of_row, axis=1)\n",
        "# end::create_additional_table_column[]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cebebdb",
      "metadata": {
        "id": "7cebebdb",
        "outputId": "f059298b-3e51-447b-fbd4-d1fa3fd96c5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    The candidate 39 years old is working in the\\n...\n",
              "1    The candidate 50 years old is working in the\\n...\n",
              "2    The candidate 38 years old is working in the\\n...\n",
              "3    The candidate 53 years old is working in the\\n...\n",
              "4    The candidate 28 years old is working in the\\n...\n",
              "Name: text_description, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The candidate 39 years old is working in the\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The candidate 50 years old is working in the\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The candidate 38 years old is working in the\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The candidate 53 years old is working in the\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The candidate 28 years old is working in the\\n...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Display the first 5 text_description of the dataset\n",
        "df_extended[\"text_description\"].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1296a62a",
      "metadata": {
        "id": "1296a62a",
        "outputId": "8f3f6d7f-2504-4462-cc80-4663cf83c57e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The candidate 39 years old is working in the\\n            State-gov sector. The candidate was born in\\n            United-States, is Never-married\\n            and has a Not-in-family relationship.\\n            The candidate has a Bachelors degree\\n            and is working as a Adm-clerical.\\n            The income of the candidate is <=50K.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "df_extended[\"text_description\"][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72751749",
      "metadata": {
        "id": "72751749"
      },
      "source": [
        "## 1.4 Querying a PostgreSQL Database"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98c9bbbe",
      "metadata": {
        "id": "98c9bbbe"
      },
      "source": [
        "```\n",
        "CREATE USER rag_user WITH PASSWORD 'raguserpassword123';\n",
        "GRANT ALL ON ALL TABLES IN SCHEMA public TO rag_user;\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c3c88c4",
      "metadata": {
        "id": "2c3c88c4"
      },
      "outputs": [],
      "source": [
        "\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "################################################################################\n",
        "# Querying the postgres database using SQLAlchemy\n",
        "################################################################################\n",
        "\n",
        "\n",
        "username = os.getenv(\"POSTGRESQL_USER\")  # Your PostgreSQL username\n",
        "password = os.getenv(\"POSTGRESQL_PASSWORD\")  # Your PostgreSQL password\n",
        "host = os.getenv(\"DB_HOST\", \"localhost\")  # Default to localhost if not provided\n",
        "port = os.getenv(\"DB_PORT\", \"5432\")  # Default to 5432 if not provided\n",
        "database = os.getenv(\"DB_NAME\", \"postgres\")  # Database name (e.g., postgres)\n",
        "\n",
        "# tag::query_postgres[]\n",
        "import os\n",
        "import pandas as pd\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "connection_string = (\n",
        "    f\"postgresql+psycopg2://{username}:{password}@{host}:{port}/{database}\"\n",
        ")\n",
        "engine = create_engine(connection_string)\n",
        "\n",
        "with engine.connect() as connection:\n",
        "    query = \"\"\"SELECT * FROM categories ORDER BY category_id ASC \"\"\"\n",
        "    result = pd.read_sql(query, connection)\n",
        "    print(result)\n",
        "# end::query_postgres[]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bbc42f7",
      "metadata": {
        "id": "4bbc42f7"
      },
      "source": [
        "### 1.5 Loading Audio Files by Using Speech-to-Text Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfd28b4f",
      "metadata": {
        "id": "bfd28b4f"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "import openai\n",
        "\n",
        "# Set OPENAI_API_KEY environment variable using the value from the .env file\n",
        "load_dotenv()\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# tag::transform_audio_to_text[]\n",
        "import os\n",
        "import openai\n",
        "\n",
        "audio_file_path = \"../datasets/audio_files/harvard.wav\"\n",
        "\n",
        "# initialize the OpenAI client with your API key\n",
        "client = openai.OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "with open(audio_file_path, \"rb\") as audio_file:\n",
        "    transcription = client.audio.transcriptions.create(\n",
        "        model=\"whisper-1\", file=audio_file\n",
        "    )\n",
        "# end::transform_audio_to_text[]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52742c98",
      "metadata": {
        "id": "52742c98",
        "outputId": "84d91ae7-dd0e-4628-8f2f-0257effcb0e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Transcription(text='The stale smell of old beer lingers. It takes heat to bring out the odor. A cold dip restores health and zest. A salt pickle tastes fine with ham. Tacos al pastor are my favorite. A zestful food is the hot cross bun.', logprobs=None)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transcription"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea003db8",
      "metadata": {
        "id": "ea003db8"
      },
      "source": [
        "### 1.6 Extracting Text from Images and PDFs Using OCR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c4b2df0",
      "metadata": {
        "id": "3c4b2df0",
        "outputId": "bf4c4073-0b47-4aed-eb1f-0e24b7a30bcb"
      },
      "outputs": [
        {
          "ename": "TesseractNotFoundError",
          "evalue": "tesseract is not installed or it's not in your PATH. See README file for more information.",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\z004j58u\\repos\\others\\rag-oreily-book\\.venv_ch01_loading_data\\Lib\\site-packages\\pytesseract\\pytesseract.py:275\u001b[39m, in \u001b[36mrun_tesseract\u001b[39m\u001b[34m(input_filename, output_filename_base, extension, lang, config, nice, timeout)\u001b[39m\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m275\u001b[39m     proc = \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msubprocess_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    276\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py:1038\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[39m\n\u001b[32m   1035\u001b[39m             \u001b[38;5;28mself\u001b[39m.stderr = io.TextIOWrapper(\u001b[38;5;28mself\u001b[39m.stderr,\n\u001b[32m   1036\u001b[39m                     encoding=encoding, errors=errors)\n\u001b[32m-> \u001b[39m\u001b[32m1038\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1039\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1040\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1041\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1042\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1043\u001b[39m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1044\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1045\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1046\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1047\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m   1048\u001b[39m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py:1550\u001b[39m, in \u001b[36mPopen._execute_child\u001b[39m\u001b[34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session, unused_process_group)\u001b[39m\n\u001b[32m   1549\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1550\u001b[39m     hp, ht, pid, tid = \u001b[43m_winapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCreateProcess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1551\u001b[39m \u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# no special security\u001b[39;49;00m\n\u001b[32m   1552\u001b[39m \u001b[43m                             \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1553\u001b[39m \u001b[43m                             \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1554\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1555\u001b[39m \u001b[43m                             \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1556\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1557\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1558\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1559\u001b[39m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[32m   1560\u001b[39m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1563\u001b[39m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[32m   1564\u001b[39m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n",
            "\u001b[31mFileNotFoundError\u001b[39m: [WinError 2] The system cannot find the file specified",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[31mTesseractNotFoundError\u001b[39m                    Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m image = Image.open(fp=\u001b[33m\"\u001b[39m\u001b[33m../datasets/images/example_finance_reporting_slide.png\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Use Tesseracst to do OCR on the image\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m text = \u001b[43mpytesseract\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimage_to_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# end::extract_text_from_financial_reporting_slide_tesseract[]\u001b[39;00m\n\u001b[32m     13\u001b[39m \n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m###########################################################################################################\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Define the file path to the Word document\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m###########################################################################################################\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# tag::extract_text_from_images[]\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\z004j58u\\repos\\others\\rag-oreily-book\\.venv_ch01_loading_data\\Lib\\site-packages\\pytesseract\\pytesseract.py:486\u001b[39m, in \u001b[36mimage_to_string\u001b[39m\u001b[34m(image, lang, config, nice, output_type, timeout)\u001b[39m\n\u001b[32m    481\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    482\u001b[39m \u001b[33;03mReturns the result of a Tesseract OCR run on the provided image to string\u001b[39;00m\n\u001b[32m    483\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    484\u001b[39m args = [image, \u001b[33m'\u001b[39m\u001b[33mtxt\u001b[39m\u001b[33m'\u001b[39m, lang, config, nice, timeout]\n\u001b[32m--> \u001b[39m\u001b[32m486\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m{\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m    \u001b[49m\u001b[43mOutput\u001b[49m\u001b[43m.\u001b[49m\u001b[43mBYTES\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[43mOutput\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDICT\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43mOutput\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSTRING\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m\u001b[49m\u001b[43m}\u001b[49m\u001b[43m[\u001b[49m\u001b[43moutput_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\z004j58u\\repos\\others\\rag-oreily-book\\.venv_ch01_loading_data\\Lib\\site-packages\\pytesseract\\pytesseract.py:489\u001b[39m, in \u001b[36mimage_to_string.<locals>.<lambda>\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    481\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    482\u001b[39m \u001b[33;03mReturns the result of a Tesseract OCR run on the provided image to string\u001b[39;00m\n\u001b[32m    483\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    484\u001b[39m args = [image, \u001b[33m'\u001b[39m\u001b[33mtxt\u001b[39m\u001b[33m'\u001b[39m, lang, config, nice, timeout]\n\u001b[32m    486\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m    487\u001b[39m     Output.BYTES: \u001b[38;5;28;01mlambda\u001b[39;00m: run_and_get_output(*(args + [\u001b[38;5;28;01mTrue\u001b[39;00m])),\n\u001b[32m    488\u001b[39m     Output.DICT: \u001b[38;5;28;01mlambda\u001b[39;00m: {\u001b[33m'\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m'\u001b[39m: run_and_get_output(*args)},\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m     Output.STRING: \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    490\u001b[39m }[output_type]()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\z004j58u\\repos\\others\\rag-oreily-book\\.venv_ch01_loading_data\\Lib\\site-packages\\pytesseract\\pytesseract.py:352\u001b[39m, in \u001b[36mrun_and_get_output\u001b[39m\u001b[34m(image, extension, lang, config, nice, timeout, return_bytes)\u001b[39m\n\u001b[32m    341\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m save(image) \u001b[38;5;28;01mas\u001b[39;00m (temp_name, input_filename):\n\u001b[32m    342\u001b[39m     kwargs = {\n\u001b[32m    343\u001b[39m         \u001b[33m'\u001b[39m\u001b[33minput_filename\u001b[39m\u001b[33m'\u001b[39m: input_filename,\n\u001b[32m    344\u001b[39m         \u001b[33m'\u001b[39m\u001b[33moutput_filename_base\u001b[39m\u001b[33m'\u001b[39m: temp_name,\n\u001b[32m   (...)\u001b[39m\u001b[32m    349\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m'\u001b[39m: timeout,\n\u001b[32m    350\u001b[39m     }\n\u001b[32m--> \u001b[39m\u001b[32m352\u001b[39m     \u001b[43mrun_tesseract\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    353\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _read_output(\n\u001b[32m    354\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs[\u001b[33m'\u001b[39m\u001b[33moutput_filename_base\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mextsep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mextension\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    355\u001b[39m         return_bytes,\n\u001b[32m    356\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\z004j58u\\repos\\others\\rag-oreily-book\\.venv_ch01_loading_data\\Lib\\site-packages\\pytesseract\\pytesseract.py:280\u001b[39m, in \u001b[36mrun_tesseract\u001b[39m\u001b[34m(input_filename, output_filename_base, extension, lang, config, nice, timeout)\u001b[39m\n\u001b[32m    278\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m    279\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m280\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m TesseractNotFoundError()\n\u001b[32m    282\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m timeout_manager(proc, timeout) \u001b[38;5;28;01mas\u001b[39;00m error_string:\n\u001b[32m    283\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m proc.returncode:\n",
            "\u001b[31mTesseractNotFoundError\u001b[39m: tesseract is not installed or it's not in your PATH. See README file for more information."
          ]
        }
      ],
      "source": [
        "# tag::extract_text_from_financial_reporting_slide_tesseract[]\n",
        "import os\n",
        "from pdf2image import convert_from_path\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "\n",
        "# Load the sample .png file\n",
        "image = Image.open(fp=\"../datasets/images/example_finance_reporting_slide.png\")\n",
        "\n",
        "# Use Tesseracst to do OCR on the image\n",
        "text = pytesseract.image_to_string(image)\n",
        "# end::extract_text_from_financial_reporting_slide_tesseract[]\n",
        "\n",
        "###########################################################################################################\n",
        "# Define the file path to the Word document\n",
        "###########################################################################################################\n",
        "# tag::extract_text_from_images[]\n",
        "import os\n",
        "from pdf2image import convert_from_path\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "\n",
        "file_path = \"../datasets/images/2023_Jan_7_Feature_Engineering_Techniques.pdf\"\n",
        "\n",
        "# Convert PDF to a list of images\n",
        "images = convert_from_path(pdf_path=file_path)\n",
        "\n",
        "text = []\n",
        "for i, image in enumerate(images):\n",
        "    page_text = pytesseract.image_to_string(image)\n",
        "    text.append(page_text)\n",
        "# end::extract_text_from_images[]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2986fa73",
      "metadata": {
        "id": "2986fa73"
      },
      "source": [
        "### 1.7 Extracting Text from Images using Multimodal Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71798de0",
      "metadata": {
        "id": "71798de0"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "import openai\n",
        "# Set OPENAI_API_KEY environment variable using the value from the .env file\n",
        "load_dotenv()\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# tag::extract_text_from_financial_reporting_slide[]\n",
        "import os\n",
        "from PIL import Image\n",
        "import base64\n",
        "import openai\n",
        "\n",
        "png_file_path = \"../datasets/images/example_finance_reporting_slide.png\"\n",
        "\n",
        "with open(png_file_path, \"rb\") as image_file:\n",
        "    base64_image = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
        "\n",
        "    prompt = (\n",
        "        \"Extract the text from the image attached. Make sure to only \"\n",
        "        \"extract only the text. If there is no text in the image, \"\n",
        "        \"please return with the sentence 'No text found in the image.\"\n",
        "    )\n",
        "\n",
        "    response = openai.chat.completions.create(\n",
        "        model=\"gpt-4o\",  # define the model to use\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\"type\": \"text\", \"text\": prompt},\n",
        "                    {\n",
        "                        \"type\": \"image_url\",\n",
        "                        \"image_url\": {\n",
        "                            \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
        "                        },\n",
        "                    },\n",
        "                ],\n",
        "            }\n",
        "        ],\n",
        "        max_tokens=500,\n",
        "    )\n",
        "\n",
        "    content = response.choices[0].message.content\n",
        "# end::extract_text_from_financial_reporting_slide[]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5eff671a",
      "metadata": {
        "id": "5eff671a"
      },
      "source": [
        "### 1.8 Generating Text Summaries for Images Using Multimodal Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bec5eee2",
      "metadata": {
        "id": "bec5eee2"
      },
      "outputs": [],
      "source": [
        "# Load the environment variables from the .env file\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# tag::generate_text_summaries_for_images[]\n",
        "import base64\n",
        "import openai\n",
        "\n",
        "image_path = \"../datasets/images/vietnam.png\"\n",
        "\n",
        "with open(image_path, \"rb\") as image_file:\n",
        "    base64_image = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
        "\n",
        "    prompt = (\n",
        "        \"You are an assistant for visually impaired users. \"\n",
        "        \"Describe the image in detail.\"\n",
        "    )\n",
        "\n",
        "    response = openai.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\"type\": \"text\", \"text\": prompt},\n",
        "                    {\n",
        "                        \"type\": \"image_url\",\n",
        "                        \"image_url\": {\n",
        "                            \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
        "                        },\n",
        "                    },\n",
        "                ],\n",
        "            }\n",
        "        ],\n",
        "        max_tokens=150,\n",
        "    )\n",
        "\n",
        "    content = response.choices[0].message.content\n",
        "# end::generate_text_summaries_for_images[]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f347f47b",
      "metadata": {
        "id": "f347f47b",
        "outputId": "2179f204-9b22-4bd2-a8ae-dd2a2a31cf32"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The image depicts a city skyline at dusk, with the sky exhibiting shades of blue and purple. Prominent modern skyscrapers line the scene, with the tallest building having a distinctive sharp spire and bright lights at the top. Another nearby building has a unique curved top with a protruding structure. The buildings are a mix of glass and steel, reflecting the evening lights.\\n\\nIn front of the skyline, there is a calm body of water that mirror the lights and colors from the buildings. On the left side, a brightly lit dock or platform juts into the water, adding a touch of yellow from the artificial lights. The overall ambience is serene, with the city coming to life as daylight fades.'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "content"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fde1cea8",
      "metadata": {
        "id": "fde1cea8"
      },
      "source": [
        "### 1.9 Generating Text Summaries for Embedded Tables Using Multimodal Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb60ee0b",
      "metadata": {
        "id": "eb60ee0b",
        "outputId": "c7436f9e-9694-49f5-82e4-fc4ed92f8c7d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\z004j58u\\repos\\others\\rag-oreily-book\\.venv_ch01_loading_data\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "Failed to get OCRAgent instance: No module named 'unstructured_pytesseract'\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Could not get the OCRAgent instance. Please check the OCR package and the OCR_AGENT environment variable.",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\z004j58u\\repos\\others\\rag-oreily-book\\.venv_ch01_loading_data\\Lib\\site-packages\\unstructured\\partition\\utils\\ocr_models\\ocr_interface.py:47\u001b[39m, in \u001b[36mOCRAgent.get_instance\u001b[39m\u001b[34m(ocr_agent_module, language)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     module = \u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m     loaded_class = \u001b[38;5;28mgetattr\u001b[39m(module, class_name)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\importlib\\__init__.py:88\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m     87\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1387\u001b[39m, in \u001b[36m_gcd_import\u001b[39m\u001b[34m(name, package, level)\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1360\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1331\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:935\u001b[39m, in \u001b[36m_load_unlocked\u001b[39m\u001b[34m(spec)\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1026\u001b[39m, in \u001b[36mexec_module\u001b[39m\u001b[34m(self, module)\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:488\u001b[39m, in \u001b[36m_call_with_frames_removed\u001b[39m\u001b[34m(f, *args, **kwds)\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\z004j58u\\repos\\others\\rag-oreily-book\\.venv_ch01_loading_data\\Lib\\site-packages\\unstructured\\partition\\utils\\ocr_models\\tesseract_ocr.py:10\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munstructured_pytesseract\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlxml\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m etree\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'unstructured_pytesseract'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m texts = []\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# partition the PDF file into its elements\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m raw_pdf_elements = \u001b[43mpartition_pdf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpdf_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhi_res\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m element \u001b[38;5;129;01min\u001b[39;00m raw_pdf_elements:\n\u001b[32m     17\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33munstructured.documents.elements.Table\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mtype\u001b[39m(element)):\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\z004j58u\\repos\\others\\rag-oreily-book\\.venv_ch01_loading_data\\Lib\\site-packages\\unstructured\\documents\\elements.py:585\u001b[39m, in \u001b[36mprocess_metadata.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    583\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    584\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args: _P.args, **kwargs: _P.kwargs) -> \u001b[38;5;28mlist\u001b[39m[Element]:\n\u001b[32m--> \u001b[39m\u001b[32m585\u001b[39m     elements = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    586\u001b[39m     call_args = get_call_args_applying_defaults(func, *args, **kwargs)\n\u001b[32m    588\u001b[39m     unique_element_ids: \u001b[38;5;28mbool\u001b[39m = call_args.get(\u001b[33m\"\u001b[39m\u001b[33munique_element_ids\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\z004j58u\\repos\\others\\rag-oreily-book\\.venv_ch01_loading_data\\Lib\\site-packages\\unstructured\\file_utils\\filetype.py:816\u001b[39m, in \u001b[36madd_filetype.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    814\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    815\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args: _P.args, **kwargs: _P.kwargs) -> \u001b[38;5;28mlist\u001b[39m[Element]:\n\u001b[32m--> \u001b[39m\u001b[32m816\u001b[39m     elements = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    818\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m element \u001b[38;5;129;01min\u001b[39;00m elements:\n\u001b[32m    819\u001b[39m         \u001b[38;5;66;03m# NOTE(robinson) - Attached files have already run through this logic\u001b[39;00m\n\u001b[32m    820\u001b[39m         \u001b[38;5;66;03m# in their own partitioning function\u001b[39;00m\n\u001b[32m    821\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m element.metadata.attached_to_filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\z004j58u\\repos\\others\\rag-oreily-book\\.venv_ch01_loading_data\\Lib\\site-packages\\unstructured\\file_utils\\filetype.py:774\u001b[39m, in \u001b[36madd_metadata.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    772\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    773\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args: _P.args, **kwargs: _P.kwargs) -> \u001b[38;5;28mlist\u001b[39m[Element]:\n\u001b[32m--> \u001b[39m\u001b[32m774\u001b[39m     elements = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    775\u001b[39m     call_args = get_call_args_applying_defaults(func, *args, **kwargs)\n\u001b[32m    777\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m call_args.get(\u001b[33m\"\u001b[39m\u001b[33mmetadata_filename\u001b[39m\u001b[33m\"\u001b[39m):\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\z004j58u\\repos\\others\\rag-oreily-book\\.venv_ch01_loading_data\\Lib\\site-packages\\unstructured\\chunking\\dispatch.py:74\u001b[39m, in \u001b[36madd_chunking_strategy.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"The decorated function is replaced with this one.\"\"\"\u001b[39;00m\n\u001b[32m     73\u001b[39m \u001b[38;5;66;03m# -- call the partitioning function to get the elements --\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m elements = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[38;5;66;03m# -- look for a chunking-strategy argument --\u001b[39;00m\n\u001b[32m     77\u001b[39m call_args = get_call_args_applying_defaults(func, *args, **kwargs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\z004j58u\\repos\\others\\rag-oreily-book\\.venv_ch01_loading_data\\Lib\\site-packages\\unstructured\\partition\\pdf.py:228\u001b[39m, in \u001b[36mpartition_pdf\u001b[39m\u001b[34m(filename, file, include_page_breaks, strategy, infer_table_structure, ocr_languages, languages, metadata_filename, metadata_last_modified, chunking_strategy, hi_res_model_name, extract_images_in_pdf, extract_image_block_types, extract_image_block_output_dir, extract_image_block_to_payload, starting_page_number, extract_forms, form_extraction_skip_tables, password, pdfminer_line_margin, pdfminer_char_margin, pdfminer_line_overlap, pdfminer_word_margin, **kwargs)\u001b[39m\n\u001b[32m    225\u001b[39m exactly_one(filename=filename, file=file)\n\u001b[32m    227\u001b[39m languages = check_language_args(languages \u001b[38;5;129;01mor\u001b[39;00m [], ocr_languages)\n\u001b[32m--> \u001b[39m\u001b[32m228\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpartition_pdf_or_image\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    230\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[43m    \u001b[49m\u001b[43minclude_page_breaks\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude_page_breaks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[43m    \u001b[49m\u001b[43minfer_table_structure\u001b[49m\u001b[43m=\u001b[49m\u001b[43minfer_table_structure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlanguages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlanguages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata_last_modified\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata_last_modified\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhi_res_model_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhi_res_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextract_images_in_pdf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextract_images_in_pdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextract_image_block_types\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextract_image_block_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextract_image_block_output_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextract_image_block_output_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextract_image_block_to_payload\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextract_image_block_to_payload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstarting_page_number\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstarting_page_number\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextract_forms\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextract_forms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m    \u001b[49m\u001b[43mform_extraction_skip_tables\u001b[49m\u001b[43m=\u001b[49m\u001b[43mform_extraction_skip_tables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpassword\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpdfminer_line_margin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpdfminer_line_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpdfminer_char_margin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpdfminer_char_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpdfminer_line_overlap\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpdfminer_line_overlap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpdfminer_word_margin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpdfminer_word_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\z004j58u\\repos\\others\\rag-oreily-book\\.venv_ch01_loading_data\\Lib\\site-packages\\unstructured\\partition\\pdf.py:341\u001b[39m, in \u001b[36mpartition_pdf_or_image\u001b[39m\u001b[34m(filename, file, is_image, include_page_breaks, strategy, infer_table_structure, languages, metadata_last_modified, hi_res_model_name, extract_images_in_pdf, extract_image_block_types, extract_image_block_output_dir, extract_image_block_to_payload, starting_page_number, extract_forms, form_extraction_skip_tables, password, pdfminer_line_margin, pdfminer_char_margin, pdfminer_line_overlap, pdfminer_word_margin, ocr_agent, table_ocr_agent, **kwargs)\u001b[39m\n\u001b[32m    339\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m warnings.catch_warnings():\n\u001b[32m    340\u001b[39m         warnings.simplefilter(\u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m341\u001b[39m         elements = \u001b[43m_partition_pdf_or_image_local\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    343\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m=\u001b[49m\u001b[43mspooled_to_bytes_io_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    344\u001b[39m \u001b[43m            \u001b[49m\u001b[43mis_image\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_image\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    345\u001b[39m \u001b[43m            \u001b[49m\u001b[43minfer_table_structure\u001b[49m\u001b[43m=\u001b[49m\u001b[43minfer_table_structure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    346\u001b[39m \u001b[43m            \u001b[49m\u001b[43minclude_page_breaks\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude_page_breaks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlanguages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlanguages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m            \u001b[49m\u001b[43mocr_languages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mocr_languages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata_last_modified\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata_last_modified\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlast_modified\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhi_res_model_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhi_res_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpdf_text_extractable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpdf_text_extractable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextract_images_in_pdf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextract_images_in_pdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextract_image_block_types\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextract_image_block_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextract_image_block_output_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextract_image_block_output_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextract_image_block_to_payload\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextract_image_block_to_payload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstarting_page_number\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstarting_page_number\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextract_forms\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextract_forms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m            \u001b[49m\u001b[43mform_extraction_skip_tables\u001b[49m\u001b[43m=\u001b[49m\u001b[43mform_extraction_skip_tables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpassword\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpassword\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpdfminer_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpdfminer_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m            \u001b[49m\u001b[43mocr_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mocr_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtable_ocr_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtable_ocr_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    363\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    364\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    365\u001b[39m         out_elements = _process_uncategorized_text_elements(elements)\n\u001b[32m    367\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m strategy == PartitionStrategy.FAST:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\z004j58u\\repos\\others\\rag-oreily-book\\.venv_ch01_loading_data\\Lib\\site-packages\\unstructured\\utils.py:216\u001b[39m, in \u001b[36mrequires_dependencies.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args: _P.args, **kwargs: _P.kwargs):\n\u001b[32m    215\u001b[39m     run_check()\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\z004j58u\\repos\\others\\rag-oreily-book\\.venv_ch01_loading_data\\Lib\\site-packages\\unstructured\\partition\\pdf.py:690\u001b[39m, in \u001b[36m_partition_pdf_or_image_local\u001b[39m\u001b[34m(filename, file, is_image, infer_table_structure, include_page_breaks, languages, ocr_languages, ocr_mode, model_name, hi_res_model_name, pdf_image_dpi, metadata_last_modified, pdf_text_extractable, extract_images_in_pdf, extract_image_block_types, extract_image_block_output_dir, extract_image_block_to_payload, analysis, analyzed_image_output_dir_path, starting_page_number, extract_forms, form_extraction_skip_tables, pdf_hi_res_max_pages, password, pdfminer_config, ocr_agent, table_ocr_agent, **kwargs)\u001b[39m\n\u001b[32m    683\u001b[39m     \u001b[38;5;66;03m# NOTE(christine): merged_document_layout = extracted_layout + inferred_layout\u001b[39;00m\n\u001b[32m    684\u001b[39m     merged_document_layout = merge_inferred_with_extracted_layout(\n\u001b[32m    685\u001b[39m         inferred_document_layout=inferred_document_layout,\n\u001b[32m    686\u001b[39m         extracted_layout=extracted_layout,\n\u001b[32m    687\u001b[39m         hi_res_model_name=hi_res_model_name,\n\u001b[32m    688\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m690\u001b[39m     final_document_layout = \u001b[43mprocess_file_with_ocr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    692\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmerged_document_layout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    693\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextracted_layout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextracted_layout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    694\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_image\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_image\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    695\u001b[39m \u001b[43m        \u001b[49m\u001b[43minfer_table_structure\u001b[49m\u001b[43m=\u001b[49m\u001b[43minfer_table_structure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m        \u001b[49m\u001b[43mocr_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mocr_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[43m        \u001b[49m\u001b[43mocr_languages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mocr_languages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[43m        \u001b[49m\u001b[43mocr_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mocr_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    699\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpdf_image_dpi\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpdf_image_dpi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[43m        \u001b[49m\u001b[43mocr_layout_dumper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mocr_layout_dumper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    701\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpassword\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpassword\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtable_ocr_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtable_ocr_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    704\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    705\u001b[39m     inferred_document_layout = process_data_with_model(\n\u001b[32m    706\u001b[39m         file,\n\u001b[32m    707\u001b[39m         is_image=is_image,\n\u001b[32m   (...)\u001b[39m\u001b[32m    710\u001b[39m         password=password,\n\u001b[32m    711\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\z004j58u\\repos\\others\\rag-oreily-book\\.venv_ch01_loading_data\\Lib\\site-packages\\unstructured\\utils.py:216\u001b[39m, in \u001b[36mrequires_dependencies.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args: _P.args, **kwargs: _P.kwargs):\n\u001b[32m    215\u001b[39m     run_check()\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\z004j58u\\repos\\others\\rag-oreily-book\\.venv_ch01_loading_data\\Lib\\site-packages\\unstructured\\partition\\pdf_image\\ocr.py:201\u001b[39m, in \u001b[36mprocess_file_with_ocr\u001b[39m\u001b[34m(filename, out_layout, extracted_layout, is_image, infer_table_structure, ocr_agent, ocr_languages, ocr_mode, pdf_image_dpi, ocr_layout_dumper, password, table_ocr_agent)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m os.path.isdir(filename) \u001b[38;5;129;01mor\u001b[39;00m os.path.isfile(filename):\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    203\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mFile \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m not found!\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\z004j58u\\repos\\others\\rag-oreily-book\\.venv_ch01_loading_data\\Lib\\site-packages\\unstructured\\partition\\pdf_image\\ocr.py:186\u001b[39m, in \u001b[36mprocess_file_with_ocr\u001b[39m\u001b[34m(filename, out_layout, extracted_layout, is_image, infer_table_structure, ocr_agent, ocr_languages, ocr_mode, pdf_image_dpi, ocr_layout_dumper, password, table_ocr_agent)\u001b[39m\n\u001b[32m    184\u001b[39m     extracted_regions = extracted_layout[i] \u001b[38;5;28;01mif\u001b[39;00m i < \u001b[38;5;28mlen\u001b[39m(extracted_layout) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    185\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m PILImage.open(image_path) \u001b[38;5;28;01mas\u001b[39;00m image:\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m         merged_page_layout = \u001b[43msupplement_page_layout_with_ocr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpage_layout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout_layout\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpages\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m            \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m            \u001b[49m\u001b[43minfer_table_structure\u001b[49m\u001b[43m=\u001b[49m\u001b[43minfer_table_structure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m            \u001b[49m\u001b[43mocr_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mocr_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m            \u001b[49m\u001b[43mocr_languages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mocr_languages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m            \u001b[49m\u001b[43mocr_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mocr_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextracted_regions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextracted_regions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m            \u001b[49m\u001b[43mocr_layout_dumper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mocr_layout_dumper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtable_ocr_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtable_ocr_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    197\u001b[39m         merged_page_layouts.append(merged_page_layout)\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m DocumentLayout.from_pages(merged_page_layouts)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\z004j58u\\repos\\others\\rag-oreily-book\\.venv_ch01_loading_data\\Lib\\site-packages\\unstructured\\utils.py:216\u001b[39m, in \u001b[36mrequires_dependencies.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args: _P.args, **kwargs: _P.kwargs):\n\u001b[32m    215\u001b[39m     run_check()\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\z004j58u\\repos\\others\\rag-oreily-book\\.venv_ch01_loading_data\\Lib\\site-packages\\unstructured\\partition\\pdf_image\\ocr.py:229\u001b[39m, in \u001b[36msupplement_page_layout_with_ocr\u001b[39m\u001b[34m(page_layout, image, infer_table_structure, ocr_agent, ocr_languages, ocr_mode, extracted_regions, ocr_layout_dumper, table_ocr_agent)\u001b[39m\n\u001b[32m    227\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ocr_agent == OCR_AGENT_PADDLE:\n\u001b[32m    228\u001b[39m     language = tesseract_to_paddle_language(ocr_languages)\n\u001b[32m--> \u001b[39m\u001b[32m229\u001b[39m _ocr_agent = \u001b[43mOCRAgent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mocr_agent_module\u001b[49m\u001b[43m=\u001b[49m\u001b[43mocr_agent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    230\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ocr_mode == OCRMode.FULL_PAGE.value:\n\u001b[32m    231\u001b[39m     ocr_layout = _ocr_agent.get_layout_from_image(image)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\z004j58u\\repos\\others\\rag-oreily-book\\.venv_ch01_loading_data\\Lib\\site-packages\\unstructured\\partition\\utils\\ocr_models\\ocr_interface.py:52\u001b[39m, in \u001b[36mOCRAgent.get_instance\u001b[39m\u001b[34m(ocr_agent_module, language)\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mAttributeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     51\u001b[39m     logger.error(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to get OCRAgent instance: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     53\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCould not get the OCRAgent instance. Please check the OCR package and the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     54\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mOCR_AGENT environment variable.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     55\u001b[39m     )\n",
            "\u001b[31mRuntimeError\u001b[39m: Could not get the OCRAgent instance. Please check the OCR package and the OCR_AGENT environment variable."
          ]
        }
      ],
      "source": [
        "# tag::extract_embedded_tables_from_pdf[]\n",
        "import os\n",
        "from unstructured.partition.pdf import partition_pdf\n",
        "\n",
        "pdf_file_path = \"../datasets/pdf_files/adult_data_article.pdf\"\n",
        "\n",
        "tables = []\n",
        "texts = []\n",
        "\n",
        "# partition the PDF file into its elements\n",
        "raw_pdf_elements = partition_pdf(\n",
        "    filename=pdf_file_path,\n",
        "    strategy=\"hi_res\",\n",
        ")\n",
        "\n",
        "for element in raw_pdf_elements:\n",
        "    if \"unstructured.documents.elements.Table\" in str(type(element)):\n",
        "        tables.append(str(element))\n",
        "\n",
        "# end::extract_embedded_tables_from_pdf[]\n",
        "\n",
        "# tag::summarize_tables[]\n",
        "from openai import OpenAI\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def summarize_tables(row):\n",
        "    summary_prompt = f\"\"\"You are an assistant tasked with summarizing tables. \\\n",
        "                    Give a concise summary of the table. Table chunk: {row.table}\"\"\"\n",
        "\n",
        "    # Initialize the OpenAI API client and generate the table summary\n",
        "    client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[{\"role\": \"user\", \"content\": summary_prompt}],\n",
        "        temperature=0.7,\n",
        "        max_tokens=150,\n",
        "    )\n",
        "\n",
        "    row[\"table_summary\"] = response.choices[0].message.content\n",
        "\n",
        "    return row\n",
        "\n",
        "\n",
        "# create a pandas dataframe from the tables\n",
        "tables_df = pd.DataFrame(tables, columns=[\"table\"])\n",
        "\n",
        "# add a column to the dataframe to store the summaries\n",
        "tables_df = tables_df.apply(summarize_tables, axis=1)\n",
        "# end::summarize_tables[]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a31c4b8",
      "metadata": {
        "id": "7a31c4b8"
      },
      "outputs": [],
      "source": [
        "tables_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d42af1f0",
      "metadata": {
        "id": "d42af1f0",
        "outputId": "9be29d14-9e3a-4cc8-ee26-c7afba6f351b"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'tables_df' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 53\u001b[39m\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m answered_question\n\u001b[32m     50\u001b[39m \u001b[38;5;66;03m# generate the answer to the user's question\u001b[39;00m\n\u001b[32m     51\u001b[39m \u001b[38;5;66;03m# as context we using the first entry in the tables_df\u001b[39;00m\n\u001b[32m     52\u001b[39m answered_question = build_prompt_and_generate_answer(\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m     user_question=user_question, found_table=\u001b[43mtables_df\u001b[49m.iloc[\u001b[32m0\u001b[39m]\n\u001b[32m     54\u001b[39m )\n\u001b[32m     56\u001b[39m \u001b[38;5;28mprint\u001b[39m(answered_question)\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# end::test_ask_a_question[]\u001b[39;00m\n",
            "\u001b[31mNameError\u001b[39m: name 'tables_df' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "# tag::test_ask_a_question[]\n",
        "# define a random question to the embedded table\n",
        "user_question = \"What are the education levels of the people working in Sales?\"\n",
        "\n",
        "\n",
        "def build_prompt_and_generate_answer(user_question, found_table):\n",
        "    \"\"\"\n",
        "    This function builds a prompt using the user's question and the context of the table\n",
        "    and generates an answer using the OpenAI API\n",
        "\n",
        "    Parameters:\n",
        "        user_question: the question asked by the user\n",
        "        found_table: the table context to generate the answer from\n",
        "\n",
        "    Returns:\n",
        "        answered_question: the answer to the user's question\n",
        "    \"\"\"\n",
        "\n",
        "    question_prompt = f\"\"\"You are an assistant using the content from PDFs \\\n",
        "                        to answer questions. Below you can find the \\\n",
        "                        user's question and relevant context. Please use the \\\n",
        "                        context to generate an answer to the user's question.\n",
        "\n",
        "                        # User question: {user_question}\n",
        "\n",
        "                        # Context:\n",
        "\n",
        "                        ## Table summary:\n",
        "                        {found_table.table_summary}\n",
        "\n",
        "                        ## Table content:\n",
        "                        {found_table.table}\"\"\".stripe()\n",
        "\n",
        "    client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "    answered_question = (\n",
        "        client.chat.completions.create(\n",
        "            model=\"gpt-4o\",\n",
        "            messages=[{\"role\": \"user\", \"content\": question_prompt}],\n",
        "            temperature=0.7,\n",
        "            max_tokens=150,\n",
        "        )\n",
        "        .choices[0]\n",
        "        .message.content\n",
        "    )\n",
        "\n",
        "    return answered_question\n",
        "\n",
        "\n",
        "# generate the answer to the user's question\n",
        "# as context we using the first entry in the tables_df\n",
        "answered_question = build_prompt_and_generate_answer(\n",
        "    user_question=user_question, found_table=tables_df.iloc[0]\n",
        ")\n",
        "\n",
        "print(answered_question)\n",
        "# end::test_ask_a_question[]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ccec3c7",
      "metadata": {
        "id": "8ccec3c7"
      },
      "source": [
        "### 1.10 Parsing PDFs with Multiple Media Content Using Unstructured and Multimodal Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1c76ad1",
      "metadata": {
        "id": "b1c76ad1",
        "outputId": "c883980c-3fb1-4220-be6c-28dee41af168"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to get OCRAgent instance: No module named 'unstructured_pytesseract'\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Could not get the OCRAgent instance. Please check the OCR package and the OCR_AGENT environment variable.",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\z004j58u\\repos\\others\\rag-oreily-book\\.venv_ch01_loading_data\\Lib\\site-packages\\unstructured\\partition\\utils\\ocr_models\\ocr_interface.py:47\u001b[39m, in \u001b[36mOCRAgent.get_instance\u001b[39m\u001b[34m(ocr_agent_module, language)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     module = \u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m     loaded_class = \u001b[38;5;28mgetattr\u001b[39m(module, class_name)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\importlib\\__init__.py:88\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m     87\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1387\u001b[39m, in \u001b[36m_gcd_import\u001b[39m\u001b[34m(name, package, level)\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1360\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1331\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:935\u001b[39m, in \u001b[36m_load_unlocked\u001b[39m\u001b[34m(spec)\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1026\u001b[39m, in \u001b[36mexec_module\u001b[39m\u001b[34m(self, module)\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:488\u001b[39m, in \u001b[36m_call_with_frames_removed\u001b[39m\u001b[34m(f, *args, **kwds)\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\z004j58u\\repos\\others\\rag-oreily-book\\.venv_ch01_loading_data\\Lib\\site-packages\\unstructured\\partition\\utils\\ocr_models\\tesseract_ocr.py:10\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munstructured_pytesseract\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlxml\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m etree\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'unstructured_pytesseract'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m image_output_dir = \u001b[33m\"\u001b[39m\u001b[33m../datasets/extracted_content_from_pdfs/images\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# get elements using the function extract_pdf_elements\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m raw_pdf_elements = \u001b[43mpartition_pdf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpdf_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextract_images_in_pdf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextract_image_block_types\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mImage\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextract_image_block_to_payload\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextract_image_block_output_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimage_output_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# categorize elements by type\u001b[39;00m\n\u001b[32m     21\u001b[39m tables = []\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\z004j58u\\repos\\others\\rag-oreily-book\\.venv_ch01_loading_data\\Lib\\site-packages\\unstructured\\documents\\elements.py:585\u001b[39m, in \u001b[36mprocess_metadata.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    583\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    584\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args: _P.args, **kwargs: _P.kwargs) -> \u001b[38;5;28mlist\u001b[39m[Element]:\n\u001b[32m--> \u001b[39m\u001b[32m585\u001b[39m     elements = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    586\u001b[39m     call_args = get_call_args_applying_defaults(func, *args, **kwargs)\n\u001b[32m    588\u001b[39m     unique_element_ids: \u001b[38;5;28mbool\u001b[39m = call_args.get(\u001b[33m\"\u001b[39m\u001b[33munique_element_ids\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\z004j58u\\repos\\others\\rag-oreily-book\\.venv_ch01_loading_data\\Lib\\site-packages\\unstructured\\file_utils\\filetype.py:816\u001b[39m, in \u001b[36madd_filetype.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    814\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    815\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args: _P.args, **kwargs: _P.kwargs) -> \u001b[38;5;28mlist\u001b[39m[Element]:\n\u001b[32m--> \u001b[39m\u001b[32m816\u001b[39m     elements = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    818\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m element \u001b[38;5;129;01min\u001b[39;00m elements:\n\u001b[32m    819\u001b[39m         \u001b[38;5;66;03m# NOTE(robinson) - Attached files have already run through this logic\u001b[39;00m\n\u001b[32m    820\u001b[39m         \u001b[38;5;66;03m# in their own partitioning function\u001b[39;00m\n\u001b[32m    821\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m element.metadata.attached_to_filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\z004j58u\\repos\\others\\rag-oreily-book\\.venv_ch01_loading_data\\Lib\\site-packages\\unstructured\\file_utils\\filetype.py:774\u001b[39m, in \u001b[36madd_metadata.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    772\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    773\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args: _P.args, **kwargs: _P.kwargs) -> \u001b[38;5;28mlist\u001b[39m[Element]:\n\u001b[32m--> \u001b[39m\u001b[32m774\u001b[39m     elements = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    775\u001b[39m     call_args = get_call_args_applying_defaults(func, *args, **kwargs)\n\u001b[32m    777\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m call_args.get(\u001b[33m\"\u001b[39m\u001b[33mmetadata_filename\u001b[39m\u001b[33m\"\u001b[39m):\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\z004j58u\\repos\\others\\rag-oreily-book\\.venv_ch01_loading_data\\Lib\\site-packages\\unstructured\\chunking\\dispatch.py:74\u001b[39m, in \u001b[36madd_chunking_strategy.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"The decorated function is replaced with this one.\"\"\"\u001b[39;00m\n\u001b[32m     73\u001b[39m \u001b[38;5;66;03m# -- call the partitioning function to get the elements --\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m elements = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[38;5;66;03m# -- look for a chunking-strategy argument --\u001b[39;00m\n\u001b[32m     77\u001b[39m call_args = get_call_args_applying_defaults(func, *args, **kwargs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\z004j58u\\repos\\others\\rag-oreily-book\\.venv_ch01_loading_data\\Lib\\site-packages\\unstructured\\partition\\pdf.py:228\u001b[39m, in \u001b[36mpartition_pdf\u001b[39m\u001b[34m(filename, file, include_page_breaks, strategy, infer_table_structure, ocr_languages, languages, metadata_filename, metadata_last_modified, chunking_strategy, hi_res_model_name, extract_images_in_pdf, extract_image_block_types, extract_image_block_output_dir, extract_image_block_to_payload, starting_page_number, extract_forms, form_extraction_skip_tables, password, pdfminer_line_margin, pdfminer_char_margin, pdfminer_line_overlap, pdfminer_word_margin, **kwargs)\u001b[39m\n\u001b[32m    225\u001b[39m exactly_one(filename=filename, file=file)\n\u001b[32m    227\u001b[39m languages = check_language_args(languages \u001b[38;5;129;01mor\u001b[39;00m [], ocr_languages)\n\u001b[32m--> \u001b[39m\u001b[32m228\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpartition_pdf_or_image\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    230\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[43m    \u001b[49m\u001b[43minclude_page_breaks\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude_page_breaks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[43m    \u001b[49m\u001b[43minfer_table_structure\u001b[49m\u001b[43m=\u001b[49m\u001b[43minfer_table_structure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlanguages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlanguages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata_last_modified\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata_last_modified\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhi_res_model_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhi_res_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextract_images_in_pdf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextract_images_in_pdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextract_image_block_types\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextract_image_block_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextract_image_block_output_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextract_image_block_output_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextract_image_block_to_payload\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextract_image_block_to_payload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstarting_page_number\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstarting_page_number\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextract_forms\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextract_forms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m    \u001b[49m\u001b[43mform_extraction_skip_tables\u001b[49m\u001b[43m=\u001b[49m\u001b[43mform_extraction_skip_tables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpassword\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpdfminer_line_margin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpdfminer_line_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpdfminer_char_margin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpdfminer_char_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpdfminer_line_overlap\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpdfminer_line_overlap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpdfminer_word_margin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpdfminer_word_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\z004j58u\\repos\\others\\rag-oreily-book\\.venv_ch01_loading_data\\Lib\\site-packages\\unstructured\\partition\\pdf.py:341\u001b[39m, in \u001b[36mpartition_pdf_or_image\u001b[39m\u001b[34m(filename, file, is_image, include_page_breaks, strategy, infer_table_structure, languages, metadata_last_modified, hi_res_model_name, extract_images_in_pdf, extract_image_block_types, extract_image_block_output_dir, extract_image_block_to_payload, starting_page_number, extract_forms, form_extraction_skip_tables, password, pdfminer_line_margin, pdfminer_char_margin, pdfminer_line_overlap, pdfminer_word_margin, ocr_agent, table_ocr_agent, **kwargs)\u001b[39m\n\u001b[32m    339\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m warnings.catch_warnings():\n\u001b[32m    340\u001b[39m         warnings.simplefilter(\u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m341\u001b[39m         elements = \u001b[43m_partition_pdf_or_image_local\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    343\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m=\u001b[49m\u001b[43mspooled_to_bytes_io_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    344\u001b[39m \u001b[43m            \u001b[49m\u001b[43mis_image\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_image\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    345\u001b[39m \u001b[43m            \u001b[49m\u001b[43minfer_table_structure\u001b[49m\u001b[43m=\u001b[49m\u001b[43minfer_table_structure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    346\u001b[39m \u001b[43m            \u001b[49m\u001b[43minclude_page_breaks\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude_page_breaks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlanguages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlanguages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m            \u001b[49m\u001b[43mocr_languages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mocr_languages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata_last_modified\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata_last_modified\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlast_modified\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhi_res_model_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhi_res_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpdf_text_extractable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpdf_text_extractable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextract_images_in_pdf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextract_images_in_pdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextract_image_block_types\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextract_image_block_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextract_image_block_output_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextract_image_block_output_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextract_image_block_to_payload\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextract_image_block_to_payload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstarting_page_number\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstarting_page_number\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextract_forms\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextract_forms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m            \u001b[49m\u001b[43mform_extraction_skip_tables\u001b[49m\u001b[43m=\u001b[49m\u001b[43mform_extraction_skip_tables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpassword\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpassword\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpdfminer_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpdfminer_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m            \u001b[49m\u001b[43mocr_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mocr_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtable_ocr_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtable_ocr_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    363\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    364\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    365\u001b[39m         out_elements = _process_uncategorized_text_elements(elements)\n\u001b[32m    367\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m strategy == PartitionStrategy.FAST:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\z004j58u\\repos\\others\\rag-oreily-book\\.venv_ch01_loading_data\\Lib\\site-packages\\unstructured\\utils.py:216\u001b[39m, in \u001b[36mrequires_dependencies.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args: _P.args, **kwargs: _P.kwargs):\n\u001b[32m    215\u001b[39m     run_check()\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\z004j58u\\repos\\others\\rag-oreily-book\\.venv_ch01_loading_data\\Lib\\site-packages\\unstructured\\partition\\pdf.py:690\u001b[39m, in \u001b[36m_partition_pdf_or_image_local\u001b[39m\u001b[34m(filename, file, is_image, infer_table_structure, include_page_breaks, languages, ocr_languages, ocr_mode, model_name, hi_res_model_name, pdf_image_dpi, metadata_last_modified, pdf_text_extractable, extract_images_in_pdf, extract_image_block_types, extract_image_block_output_dir, extract_image_block_to_payload, analysis, analyzed_image_output_dir_path, starting_page_number, extract_forms, form_extraction_skip_tables, pdf_hi_res_max_pages, password, pdfminer_config, ocr_agent, table_ocr_agent, **kwargs)\u001b[39m\n\u001b[32m    683\u001b[39m     \u001b[38;5;66;03m# NOTE(christine): merged_document_layout = extracted_layout + inferred_layout\u001b[39;00m\n\u001b[32m    684\u001b[39m     merged_document_layout = merge_inferred_with_extracted_layout(\n\u001b[32m    685\u001b[39m         inferred_document_layout=inferred_document_layout,\n\u001b[32m    686\u001b[39m         extracted_layout=extracted_layout,\n\u001b[32m    687\u001b[39m         hi_res_model_name=hi_res_model_name,\n\u001b[32m    688\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m690\u001b[39m     final_document_layout = \u001b[43mprocess_file_with_ocr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    692\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmerged_document_layout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    693\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextracted_layout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextracted_layout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    694\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_image\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_image\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    695\u001b[39m \u001b[43m        \u001b[49m\u001b[43minfer_table_structure\u001b[49m\u001b[43m=\u001b[49m\u001b[43minfer_table_structure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m        \u001b[49m\u001b[43mocr_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mocr_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[43m        \u001b[49m\u001b[43mocr_languages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mocr_languages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[43m        \u001b[49m\u001b[43mocr_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mocr_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    699\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpdf_image_dpi\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpdf_image_dpi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[43m        \u001b[49m\u001b[43mocr_layout_dumper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mocr_layout_dumper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    701\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpassword\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpassword\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtable_ocr_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtable_ocr_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    704\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    705\u001b[39m     inferred_document_layout = process_data_with_model(\n\u001b[32m    706\u001b[39m         file,\n\u001b[32m    707\u001b[39m         is_image=is_image,\n\u001b[32m   (...)\u001b[39m\u001b[32m    710\u001b[39m         password=password,\n\u001b[32m    711\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\z004j58u\\repos\\others\\rag-oreily-book\\.venv_ch01_loading_data\\Lib\\site-packages\\unstructured\\utils.py:216\u001b[39m, in \u001b[36mrequires_dependencies.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args: _P.args, **kwargs: _P.kwargs):\n\u001b[32m    215\u001b[39m     run_check()\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\z004j58u\\repos\\others\\rag-oreily-book\\.venv_ch01_loading_data\\Lib\\site-packages\\unstructured\\partition\\pdf_image\\ocr.py:201\u001b[39m, in \u001b[36mprocess_file_with_ocr\u001b[39m\u001b[34m(filename, out_layout, extracted_layout, is_image, infer_table_structure, ocr_agent, ocr_languages, ocr_mode, pdf_image_dpi, ocr_layout_dumper, password, table_ocr_agent)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m os.path.isdir(filename) \u001b[38;5;129;01mor\u001b[39;00m os.path.isfile(filename):\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    203\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mFile \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m not found!\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\z004j58u\\repos\\others\\rag-oreily-book\\.venv_ch01_loading_data\\Lib\\site-packages\\unstructured\\partition\\pdf_image\\ocr.py:186\u001b[39m, in \u001b[36mprocess_file_with_ocr\u001b[39m\u001b[34m(filename, out_layout, extracted_layout, is_image, infer_table_structure, ocr_agent, ocr_languages, ocr_mode, pdf_image_dpi, ocr_layout_dumper, password, table_ocr_agent)\u001b[39m\n\u001b[32m    184\u001b[39m     extracted_regions = extracted_layout[i] \u001b[38;5;28;01mif\u001b[39;00m i < \u001b[38;5;28mlen\u001b[39m(extracted_layout) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    185\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m PILImage.open(image_path) \u001b[38;5;28;01mas\u001b[39;00m image:\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m         merged_page_layout = \u001b[43msupplement_page_layout_with_ocr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpage_layout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout_layout\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpages\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m            \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m            \u001b[49m\u001b[43minfer_table_structure\u001b[49m\u001b[43m=\u001b[49m\u001b[43minfer_table_structure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m            \u001b[49m\u001b[43mocr_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mocr_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m            \u001b[49m\u001b[43mocr_languages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mocr_languages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m            \u001b[49m\u001b[43mocr_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mocr_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextracted_regions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextracted_regions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m            \u001b[49m\u001b[43mocr_layout_dumper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mocr_layout_dumper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtable_ocr_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtable_ocr_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    197\u001b[39m         merged_page_layouts.append(merged_page_layout)\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m DocumentLayout.from_pages(merged_page_layouts)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\z004j58u\\repos\\others\\rag-oreily-book\\.venv_ch01_loading_data\\Lib\\site-packages\\unstructured\\utils.py:216\u001b[39m, in \u001b[36mrequires_dependencies.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args: _P.args, **kwargs: _P.kwargs):\n\u001b[32m    215\u001b[39m     run_check()\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\z004j58u\\repos\\others\\rag-oreily-book\\.venv_ch01_loading_data\\Lib\\site-packages\\unstructured\\partition\\pdf_image\\ocr.py:229\u001b[39m, in \u001b[36msupplement_page_layout_with_ocr\u001b[39m\u001b[34m(page_layout, image, infer_table_structure, ocr_agent, ocr_languages, ocr_mode, extracted_regions, ocr_layout_dumper, table_ocr_agent)\u001b[39m\n\u001b[32m    227\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ocr_agent == OCR_AGENT_PADDLE:\n\u001b[32m    228\u001b[39m     language = tesseract_to_paddle_language(ocr_languages)\n\u001b[32m--> \u001b[39m\u001b[32m229\u001b[39m _ocr_agent = \u001b[43mOCRAgent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mocr_agent_module\u001b[49m\u001b[43m=\u001b[49m\u001b[43mocr_agent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    230\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ocr_mode == OCRMode.FULL_PAGE.value:\n\u001b[32m    231\u001b[39m     ocr_layout = _ocr_agent.get_layout_from_image(image)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\z004j58u\\repos\\others\\rag-oreily-book\\.venv_ch01_loading_data\\Lib\\site-packages\\unstructured\\partition\\utils\\ocr_models\\ocr_interface.py:52\u001b[39m, in \u001b[36mOCRAgent.get_instance\u001b[39m\u001b[34m(ocr_agent_module, language)\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mAttributeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     51\u001b[39m     logger.error(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to get OCRAgent instance: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     53\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCould not get the OCRAgent instance. Please check the OCR package and the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     54\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mOCR_AGENT environment variable.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     55\u001b[39m     )\n",
            "\u001b[31mRuntimeError\u001b[39m: Could not get the OCRAgent instance. Please check the OCR package and the OCR_AGENT environment variable."
          ]
        }
      ],
      "source": [
        "# tag::extract_pdf_elements[]\n",
        "from unstructured.partition.pdf import partition_pdf\n",
        "import os\n",
        "\n",
        "# set the OCR agent to tesseract\n",
        "os.environ[\"OCR_AGENT\"] = \"tesseract\"\n",
        "\n",
        "pdf_file_path = \"../datasets/pdf_files/adult_data_article.pdf\"\n",
        "image_output_dir = \"../datasets/extracted_content_from_pdfs/images\"\n",
        "\n",
        "# get elements using the function extract_pdf_elements\n",
        "raw_pdf_elements = partition_pdf(\n",
        "    filename=pdf_file_path,\n",
        "    extract_images_in_pdf=True,\n",
        "    extract_image_block_types=[\"Image\", \"Table\"],\n",
        "    extract_image_block_to_payload=False,\n",
        "    extract_image_block_output_dir=image_output_dir,\n",
        ")\n",
        "\n",
        "# categorize elements by type\n",
        "tables = []\n",
        "texts = []\n",
        "titles = []\n",
        "\n",
        "# fill the just created lists with the elements\n",
        "for element in raw_pdf_elements:\n",
        "    if \"unstructured.documents.elements.Table\" in str(type(element)):\n",
        "        tables.append(str(element))\n",
        "    elif \"unstructured.documents.elements.NarrativeText\" in str(type(element)):\n",
        "        texts.append(str(element))\n",
        "    elif \"unstructured.documents.elements.Title\" in str(type(element)):\n",
        "        titles.append(str(element))\n",
        "# end::extract_pdf_elements[]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c28585d",
      "metadata": {
        "id": "9c28585d"
      },
      "source": [
        "### 1.11 Loading Videos Using Speech-to-Text and Multimodal Models"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1e7db7a",
      "metadata": {
        "id": "b1e7db7a"
      },
      "source": [
        "You can find the test video I used on YouTube: [Learn Data Science Tutorial - Full Course for Beginners](https://www.youtube.com/watch?v=ua-CiDNNj30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2aece1b",
      "metadata": {
        "id": "b2aece1b",
        "outputId": "d6fdfe93-e28c-4e48-c683-a3ef7b692db5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\z004j58u\\repos\\others\\rag-oreily-book\\.venv_ch01_loading_data\\Lib\\site-packages\\moviepy\\video\\io\\ffmpeg_reader.py:294: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  lines_video = [l for l in lines if ' Video: ' in l and re.search('\\d+x\\d+', l)]\n",
            "c:\\Users\\z004j58u\\repos\\others\\rag-oreily-book\\.venv_ch01_loading_data\\Lib\\site-packages\\moviepy\\video\\io\\ffmpeg_reader.py:367: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  rotation_lines = [l for l in lines if 'rotate          :' in l and re.search('\\d+$', l)]\n",
            "c:\\Users\\z004j58u\\repos\\others\\rag-oreily-book\\.venv_ch01_loading_data\\Lib\\site-packages\\moviepy\\video\\io\\ffmpeg_reader.py:370: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  match = re.search('\\d+$', rotation_line)\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "'../datasets/videos/learn-data-science-tutorial.mp4' not found",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\z004j58u\\repos\\others\\rag-oreily-book\\.venv_ch01_loading_data\\Lib\\site-packages\\moviepy\\video\\io\\ffmpeg_reader.py:904\u001b[39m, in \u001b[36mffmpeg_parse_infos\u001b[39m\u001b[34m(filename, check_duration, fps_source, decode_file, print_infos)\u001b[39m\n\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\z004j58u\\repos\\others\\rag-oreily-book\\.venv_ch01_loading_data\\Lib\\site-packages\\moviepy\\video\\io\\ffmpeg_reader.py:606\u001b[39m, in \u001b[36mparse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
            "\u001b[31mTypeError\u001b[39m: 'NoneType' object is not subscriptable",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m video_file_path = \u001b[33m\"\u001b[39m\u001b[33m../datasets/videos/learn-data-science-tutorial.mp4\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      8\u001b[39m image_output_folder = \u001b[33m\"\u001b[39m\u001b[33m../datasets/videos/video_extracted_images\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m clip = \u001b[43mVideoFileClip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# create a list of timestamps from which we want to extract a frame\u001b[39;00m\n\u001b[32m     13\u001b[39m time_step = \u001b[32m10\u001b[39m  \u001b[38;5;66;03m# time in seconds\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<decorator-gen-108>:2\u001b[39m, in \u001b[36m__init__\u001b[39m\u001b[34m(self, filename, decode_file, has_mask, audio, audio_buffersize, target_resolution, resize_algorithm, audio_fps, audio_nbytes, fps_source, pixel_format, is_mask)\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\z004j58u\\repos\\others\\rag-oreily-book\\.venv_ch01_loading_data\\Lib\\site-packages\\moviepy\\decorators.py:102\u001b[39m, in \u001b[36mwrapper\u001b[39m\u001b[34m(func, *args, **kwargs)\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;129m@decorator\u001b[39m.decorator\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34madd_mask_if_none\u001b[39m(f, clip, *a, **k):\n\u001b[32m    101\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\" Add a mask to the clip if there is none. \"\"\"\u001b[39;00m        \n\u001b[32m--> \u001b[39m\u001b[32m102\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m clip.mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    103\u001b[39m         clip = clip.add_mask()\n\u001b[32m    104\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m f(clip, *a, **k)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\z004j58u\\repos\\others\\rag-oreily-book\\.venv_ch01_loading_data\\Lib\\site-packages\\moviepy\\video\\io\\VideoFileClip.py:109\u001b[39m, in \u001b[36m__init__\u001b[39m\u001b[34m(self, filename, decode_file, has_mask, audio, audio_buffersize, target_resolution, resize_algorithm, audio_fps, audio_nbytes, fps_source, pixel_format, is_mask)\u001b[39m\n\u001b[32m    106\u001b[39m     mask_mf = \u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[38;5;28mself\u001b[39m.reader.get_frame(t)[:,:,\u001b[32m3\u001b[39m]/\u001b[32m255.0\u001b[39m\n\u001b[32m    107\u001b[39m     \u001b[38;5;28mself\u001b[39m.mask = (VideoClip(ismask=\u001b[38;5;28;01mTrue\u001b[39;00m, make_frame=mask_mf)\n\u001b[32m    108\u001b[39m                  .set_duration(\u001b[38;5;28mself\u001b[39m.duration))\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m     \u001b[38;5;28mself\u001b[39m.mask.fps = \u001b[38;5;28mself\u001b[39m.fps\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    113\u001b[39m     \u001b[38;5;28mself\u001b[39m.make_frame = \u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[38;5;28mself\u001b[39m.reader.get_frame(t)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\z004j58u\\repos\\others\\rag-oreily-book\\.venv_ch01_loading_data\\Lib\\site-packages\\moviepy\\video\\io\\ffmpeg_reader.py:35\u001b[39m, in \u001b[36m__init__\u001b[39m\u001b[34m(self, filename, decode_file, print_infos, bufsize, pixel_format, check_duration, target_resolution, resize_algo, fps_source)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28mself\u001b[39m.filename = filename\n\u001b[32m     34\u001b[39m \u001b[38;5;28mself\u001b[39m.proc = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m infos = ffmpeg_parse_infos(filename, print_infos, check_duration,\n\u001b[32m     36\u001b[39m                            fps_source)\n\u001b[32m     37\u001b[39m \u001b[38;5;28mself\u001b[39m.fps = infos[\u001b[33m'\u001b[39m\u001b[33mvideo_fps\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     38\u001b[39m \u001b[38;5;28mself\u001b[39m.size = infos[\u001b[33m'\u001b[39m\u001b[33mvideo_size\u001b[39m\u001b[33m'\u001b[39m]\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\z004j58u\\repos\\others\\rag-oreily-book\\.venv_ch01_loading_data\\Lib\\site-packages\\moviepy\\video\\io\\ffmpeg_reader.py:909\u001b[39m, in \u001b[36mffmpeg_parse_infos\u001b[39m\u001b[34m(filename, check_duration, fps_source, decode_file, print_infos)\u001b[39m\n\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
            "\u001b[31mFileNotFoundError\u001b[39m: '../datasets/videos/learn-data-science-tutorial.mp4' not found"
          ]
        }
      ],
      "source": [
        "\n",
        "# tag::load_video_and_extract_frames[]\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "from moviepy import VideoFileClip, TextClip, CompositeVideoClip\n",
        "\n",
        "video_file_path = \"../datasets/videos/learn-data-science-tutorial.mp4\"\n",
        "image_output_folder = \"../datasets/videos/video_extracted_images\"\n",
        "\n",
        "clip = VideoFileClip(video_file_path)\n",
        "\n",
        "# create a list of timestamps from which we want to extract a frame\n",
        "time_step = 10  # time in seconds\n",
        "timestamps = list(range(0, int(clip.duration) - time_step, time_step))\n",
        "\n",
        "# for each timestamp extract a frame\n",
        "for timestamp in timestamps:\n",
        "    frame_image_path = os.path.join(image_output_folder, f\"frame_{timestamp}.png\")\n",
        "    clip.save_frame(frame_image_path, t=timestamp)\n",
        "# end::load_video_and_extract_frames[]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75224617",
      "metadata": {
        "id": "75224617",
        "outputId": "a079b80b-4a6e-4790-d143-985fc9f3de88"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'timestamps' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# tag::video_to_audio[]\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# for each timestamp extract the audio sequence and save it to a .mp3 file\u001b[39;00m\n\u001b[32m      3\u001b[39m audio_output_folder = \u001b[33m\"\u001b[39m\u001b[33m../datasets/videos/video_extracted_audio\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m timestamp \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtimestamps\u001b[49m:\n\u001b[32m      6\u001b[39m     audio_clip = clip.subclip(timestamp, timestamp + time_step).audio\n\u001b[32m      7\u001b[39m     output_audio_path = os.path.join(audio_output_folder, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33maudio_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimestamp\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.mp3\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[31mNameError\u001b[39m: name 'timestamps' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "# tag::video_to_audio[]\n",
        "# for each timestamp extract the audio sequence and save it to a .mp3 file\n",
        "audio_output_folder = \"../datasets/videos/video_extracted_audio\"\n",
        "\n",
        "for timestamp in timestamps:\n",
        "    audio_clip = clip.subclip(timestamp, timestamp + time_step).audio\n",
        "    output_audio_path = os.path.join(audio_output_folder, f\"audio_{timestamp}.mp3\")\n",
        "    audio_clip.write_audiofile(output_audio_path)\n",
        "\n",
        "# end::video_to_audio[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "982d1de4",
      "metadata": {
        "id": "982d1de4",
        "outputId": "ff562832-eb38-434e-913a-c9efe08292ae"
      },
      "outputs": [
        {
          "ename": "BadRequestError",
          "evalue": "Error code: 400 - {'error': {'message': \"Invalid file format. Supported formats: ['flac', 'm4a', 'mp3', 'mp4', 'mpeg', 'mpga', 'oga', 'ogg', 'wav', 'webm']\", 'type': 'invalid_request_error', 'param': None, 'code': None}}",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 41\u001b[39m\n\u001b[32m     39\u001b[39m     absolut_path_audio_file = os.path.join(audio_output_folder, audio_file)\n\u001b[32m     40\u001b[39m     \u001b[38;5;66;03m# Use the function audio_to_text to convert the audio to text\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     \u001b[43maudio_to_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mabsolut_path_audio_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# end::audio_to_text[]\u001b[39;00m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36maudio_to_text\u001b[39m\u001b[34m(audio_path)\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Open and read the audio file\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(audio_path, \u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m audio_file:\n\u001b[32m     22\u001b[39m     \u001b[38;5;66;03m# Transcribe\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     transcription = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtranscriptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwhisper-1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m=\u001b[49m\u001b[43maudio_file\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# save the transcription to a text file\u001b[39;00m\n\u001b[32m     28\u001b[39m text_file_path = audio_path.replace(\u001b[33m\"\u001b[39m\u001b[33m.mp3\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m.txt\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\z004j58u\\repos\\others\\rag-oreily-book\\.venv_ch01_loading_data\\Lib\\site-packages\\openai\\_utils\\_utils.py:287\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\z004j58u\\repos\\others\\rag-oreily-book\\.venv_ch01_loading_data\\Lib\\site-packages\\openai\\resources\\audio\\transcriptions.py:333\u001b[39m, in \u001b[36mTranscriptions.create\u001b[39m\u001b[34m(self, file, model, chunking_strategy, include, language, prompt, response_format, stream, temperature, timestamp_granularities, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;66;03m# It should be noted that the actual Content-Type header that will be\u001b[39;00m\n\u001b[32m    330\u001b[39m \u001b[38;5;66;03m# sent to the server will contain a `boundary` parameter, e.g.\u001b[39;00m\n\u001b[32m    331\u001b[39m \u001b[38;5;66;03m# multipart/form-data; boundary=---abc--\u001b[39;00m\n\u001b[32m    332\u001b[39m extra_headers = {\u001b[33m\"\u001b[39m\u001b[33mContent-Type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mmultipart/form-data\u001b[39m\u001b[33m\"\u001b[39m, **(extra_headers \u001b[38;5;129;01mor\u001b[39;00m {})}\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[return-value]\u001b[39;49;00m\n\u001b[32m    334\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/audio/transcriptions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    337\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtranscription_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTranscriptionCreateParamsStreaming\u001b[49m\n\u001b[32m    338\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    339\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtranscription_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTranscriptionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    340\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    343\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    344\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    345\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_get_response_format_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    346\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mTranscriptionStreamEvent\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\z004j58u\\repos\\others\\rag-oreily-book\\.venv_ch01_loading_data\\Lib\\site-packages\\openai\\_base_client.py:1239\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1225\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1226\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1227\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1234\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1235\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1236\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1237\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1238\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1239\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\z004j58u\\repos\\others\\rag-oreily-book\\.venv_ch01_loading_data\\Lib\\site-packages\\openai\\_base_client.py:1034\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1031\u001b[39m             err.response.read()\n\u001b[32m   1033\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1034\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1036\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1038\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
            "\u001b[31mBadRequestError\u001b[39m: Error code: 400 - {'error': {'message': \"Invalid file format. Supported formats: ['flac', 'm4a', 'mp3', 'mp4', 'mpeg', 'mpga', 'oga', 'ogg', 'wav', 'webm']\", 'type': 'invalid_request_error', 'param': None, 'code': None}}"
          ]
        }
      ],
      "source": [
        "\n",
        "# tag::audio_to_text[]\n",
        "from openai import OpenAI\n",
        "\n",
        "\n",
        "def audio_to_text(audio_path):\n",
        "    \"\"\"\n",
        "    Convert audio to text using OpenAI's Whisper model.\n",
        "\n",
        "    Parameters:\n",
        "    audio_path (str): The path to the audio file.\n",
        "\n",
        "    Returns:\n",
        "    str: The text recognized from the audio.\n",
        "\n",
        "    \"\"\"\n",
        "    # Initialize the OpenAI client with your API key\n",
        "\n",
        "    client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "    # Open and read the audio file\n",
        "    with open(audio_path, \"rb\") as audio_file:\n",
        "        # Transcribe\n",
        "        transcription = client.audio.transcriptions.create(\n",
        "            model=\"whisper-1\", file=audio_file\n",
        "        )\n",
        "\n",
        "    # save the transcription to a text file\n",
        "    text_file_path = audio_path.replace(\".mp3\", \".txt\")\n",
        "    with open(text_file_path, \"w\") as text_file:\n",
        "        text_file.write(transcription.text)\n",
        "\n",
        "    return\n",
        "\n",
        "\n",
        "# List all files in folder audio_output_folder\n",
        "audio_files = os.listdir(audio_output_folder)\n",
        "\n",
        "for audio_file in audio_files:\n",
        "    absolut_path_audio_file = os.path.join(audio_output_folder, audio_file)\n",
        "    # Use the function audio_to_text to convert the audio to text\n",
        "    audio_to_text(audio_path=absolut_path_audio_file)\n",
        "# end::audio_to_text[]"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv_ch01_loading_data",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}