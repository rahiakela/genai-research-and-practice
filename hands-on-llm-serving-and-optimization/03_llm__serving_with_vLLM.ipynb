{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/genai-research-and-practice/blob/main/hands-on-llm-serving-and-optimization/03_llm__serving_with_vLLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "7-RrZxl9OvPt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vllm\n",
        "!pip install transformers"
      ],
      "metadata": {
        "id": "vwifYf3us5jz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import gc\n",
        "import time\n",
        "\n",
        "# Unload models and clean up gpu memory cache\n",
        "def free_gpu(model):\n",
        "  if model:\n",
        "    # Removes the reference to the model's memory,\n",
        "    # making it eligible for garbage collection.\n",
        "    del model\n",
        "\n",
        "  # Release any cached GPU memory that's no longer needed.\n",
        "  if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.reset_peak_memory_stats()\n",
        "\n",
        "  # Trigger garbage collection to ensure memory is fully released.\n",
        "  gc.collect()\n",
        "\n",
        "free_gpu(None)"
      ],
      "metadata": {
        "id": "ybLL8EAhRUa6"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Inference"
      ],
      "metadata": {
        "id": "k7qQ4lckO3No"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's run Qwen model with vLLM and track the inference time."
      ],
      "metadata": {
        "id": "vREEwmA2m76F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2YbOJ04uVda"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from vllm import LLM, SamplingParams\n",
        "\n",
        "model_name = \"Qwen/Qwen2.5-0.5B\"\n",
        "\n",
        "# Load model with vLLM.\n",
        "llm = LLM(model=model_name, dtype=\"float16\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the prompt.\n",
        "prompt = \"\"\"You are an expert AI historian writing a detailed chapter for a book titled \"The Evolution of Human-AI Collaboration.\"\n",
        "\n",
        "Begin by summarizing the early stages of artificial intelligence in the 1950s, touching on symbolic logic and rule-based systems. Then transition into the rise of machine learning, particularly deep learning in the 2010s.\n",
        "\n",
        "Afterward, describe how large language models like GPT transformed human-computer interaction, enabling applications in education, creative writing, customer support, and software development.\n",
        "\n",
        "Finally, reflect on the societal and ethical implications of AI, such as misinformation, bias, and the alignment problem.\n",
        "\n",
        "Write in a formal tone, with rich detail and examples in each era.\"\"\"\n",
        "\n",
        "# Create sampling parameters.\n",
        "sampling_params = SamplingParams(temperature=0.8, top_p=0.95, max_tokens=128)\n",
        "\n",
        "# Time the model generation.\n",
        "start_time = time.time()\n",
        "outputs = llm.generate([prompt], sampling_params)\n",
        "end_time = time.time()"
      ],
      "metadata": {
        "id": "kdzrcK01PG7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the results.\n",
        "for output in outputs:\n",
        "  print(f\"Generated text: {output}\")\n",
        "  print(f\"Time taken: {end_time - start_time:.2f} seconds\")"
      ],
      "metadata": {
        "id": "RYYBzAd3iK1y",
        "outputId": "2042a021-27af-4def-bcdf-47f0dd10cb18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated text: RequestOutput(request_id=0, prompt='You are an expert AI historian writing a detailed chapter for a book titled \"The Evolution of Human-AI Collaboration.\"\\n\\nBegin by summarizing the early stages of artificial intelligence in the 1950s, touching on symbolic logic and rule-based systems. Then transition into the rise of machine learning, particularly deep learning in the 2010s.\\n\\nAfterward, describe how large language models like GPT transformed human-computer interaction, enabling applications in education, creative writing, customer support, and software development.\\n\\nFinally, reflect on the societal and ethical implications of AI, such as misinformation, bias, and the alignment problem.\\n\\nWrite in a formal tone, with rich detail and examples in each era.', prompt_token_ids=[2610, 525, 458, 6203, 15235, 42968, 4378, 264, 11682, 12453, 369, 264, 2311, 24849, 330, 785, 37221, 315, 11097, 6691, 40, 86587, 2217, 11135, 553, 28285, 4849, 279, 4124, 17628, 315, 20443, 11229, 304, 279, 220, 16, 24, 20, 15, 82, 11, 30587, 389, 35296, 12218, 323, 5912, 5980, 5942, 13, 5005, 9142, 1119, 279, 10000, 315, 5662, 6832, 11, 7945, 5538, 6832, 304, 279, 220, 17, 15, 16, 15, 82, 382, 6025, 1606, 11, 7512, 1246, 3460, 4128, 4119, 1075, 479, 2828, 23507, 3738, 11476, 11281, 16230, 11, 27362, 8357, 304, 6731, 11, 11521, 4378, 11, 6002, 1824, 11, 323, 3162, 4401, 382, 23949, 11, 8708, 389, 279, 58429, 323, 30208, 24154, 315, 15235, 11, 1741, 438, 74059, 11, 15470, 11, 323, 279, 17189, 3491, 382, 7985, 304, 264, 15908, 16232, 11, 448, 9080, 7716, 323, 10295, 304, 1817, 11385, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\" Avoid slang, jargon, and complex language. Create a sense of historical context to engage readers and maintain coherence in your narrative. Title: The Evolution of Human-AI Collaboration\\n\\nThe early stages of artificial intelligence (AI) in the 1950s were marked by the development of symbolic logic and rule-based systems. In the 1960s, these technologies were extended by the creation of artificial neural networks, which were inspired by the brain's structural organization.\\n\\nSymbolic logic and rule-based systems were the foundation of AI research in the 1950s. These systems were used to represent patterns and rules\", token_ids=(34006, 79912, 11, 502, 70821, 11, 323, 6351, 4128, 13, 4230, 264, 5530, 315, 13656, 2266, 311, 16579, 12726, 323, 10306, 77825, 304, 697, 19221, 13, 10869, 25, 576, 37221, 315, 11097, 6691, 40, 86587, 271, 785, 4124, 17628, 315, 20443, 11229, 320, 15469, 8, 304, 279, 220, 16, 24, 20, 15, 82, 1033, 12864, 553, 279, 4401, 315, 35296, 12218, 323, 5912, 5980, 5942, 13, 758, 279, 220, 16, 24, 21, 15, 82, 11, 1493, 14310, 1033, 11577, 553, 279, 9688, 315, 20443, 29728, 14155, 11, 892, 1033, 14606, 553, 279, 8109, 594, 23759, 7321, 382, 15090, 292, 12218, 323, 5912, 5980, 5942, 1033, 279, 16266, 315, 15235, 3412, 304, 279, 220, 16, 24, 20, 15, 82, 13, 4220, 5942, 1033, 1483, 311, 4009, 12624, 323, 5601), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1751701474.750772, last_token_time=1751701476.372571, first_scheduled_time=1751701474.8222864, first_token_time=1751701475.398189, time_in_queue=0.07151436805725098, finished_time=1751701476.3727498, scheduler_time=0.01151036300029773, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})\n",
            "Time taken: 1.65 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "free_gpu(llm)"
      ],
      "metadata": {
        "id": "c-biu-0E4dW3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Performance Comparison"
      ],
      "metadata": {
        "id": "5SN8CIaUiVn1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's run Qwen model with standard (non-optimial) HuggingFace library and track the inference time."
      ],
      "metadata": {
        "id": "1-N2BeFliYC4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Basic Model Serving (transformers) ---\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "start_time_basic = time.time()\n",
        "\n",
        "# Load model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-0.5B\", trust_remote_code=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2.5-0.5B\", device_map=\"auto\", trust_remote_code=True)"
      ],
      "metadata": {
        "id": "XvVSbcZs3POx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the pipeline.\n",
        "generator = pipeline('text-generation', model=model, tokenizer=tokenizer)\n",
        "\n",
        "outputs_basic = generator(prompt, max_length=128, temperature=0.8, top_p=0.95)\n",
        "end_time_basic = time.time()"
      ],
      "metadata": {
        "id": "pvXfx61winYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n---- Basic Model Serving Results ----\")\n",
        "for output in outputs_basic:\n",
        "    print(f\"Generated text: {output['generated_text']}\")\n",
        "    print(f\"Time taken: {end_time_basic - start_time_basic:.2f} seconds\")\n",
        "\n",
        "# print(f\"\\nLatency difference: {(end_time_basic - start_time_basic) - (end_time - start_time):.2f} seconds\")\n",
        "\n",
        "free_gpu(generator)"
      ],
      "metadata": {
        "id": "0xiBHzrKipoS",
        "outputId": "cdcf62ea-95ff-40d8-9e34-88cdd2c669c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---- Basic Model Serving Results ----\n",
            "Generated text: You are an expert AI historian writing a detailed chapter for a book titled \"The Evolution of Human-AI Collaboration.\"\n",
            "\n",
            "Begin by summarizing the early stages of artificial intelligence in the 1950s, touching on symbolic logic and rule-based systems. Then transition into the rise of machine learning, particularly deep learning in the 2010s.\n",
            "\n",
            "Afterward, describe how large language models like GPT transformed human-computer interaction, enabling applications in education, creative writing, customer support, and software development.\n",
            "\n",
            "Finally, reflect on the societal and ethical implications of AI, such as misinformation, bias, and the alignment problem.\n",
            "\n",
            "Write in a formal tone, with rich detail and examples in each era. a summary of 800 words. The evolution of human-AI collaboration during the early 1950s was marked by a significant breakthrough in artificial intelligence known as symbolic logic and rule-based systems. These early AI systems relied on formal rules and logical reasoning to make decisions, which set the foundation for the development of more sophisticated AI technologies.\n",
            "\n",
            "In the 1960s, symbolic logic and rule-based systems became the dominant paradigm for AI. These systems allowed computers to interact with humans in a logical and structured manner, enabling programs to make decisions and solve problems based on predefined rules. The most famous example of symbolic logic and rule-based systems is the Turing machine, which is still used today in computer science and artificial intelligence research.\n",
            "\n",
            "As symbolic logic and rule-based systems matured, machine learning emerged as a new area of AI research. Machine learning algorithms, including supervised and unsupervised learning, allow computers to learn from data and make predictions or decisions based on that data. Deep learning, a specific type of machine learning, achieved significant breakthroughs in the early 2000s, enabling computers to recognize patterns and make more accurate predictions than ever before.\n",
            "\n",
            "Large language models, such as GPT, transformed human-computer interaction by enabling applications in education\n",
            "Time taken: 52.17 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\nLatency difference: {(end_time_basic - start_time_basic) - (end_time - start_time):.2f} seconds\")\n"
      ],
      "metadata": {
        "id": "h0vy2RHyczoa",
        "outputId": "d85c739d-8717-4137-e75c-0bb27dd70ec6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Latency difference: 50.52 seconds\n"
          ]
        }
      ]
    }
  ]
}