{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/genai-research-and-practice/blob/main/building-natural-language-and-llm-pipelines/02-diving-deep-into-llm/jupyter-notebooks/02_create-simple-agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1b26349",
      "metadata": {
        "id": "f1b26349"
      },
      "source": [
        "üîß **Setup Required**: Before running this notebook, please follow the [setup instructions](../README.md#setup-instructions) to configure your environment and API keys."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c539e8a3",
      "metadata": {
        "id": "c539e8a3"
      },
      "source": [
        "# Your First AI Agent: Getting Started\n",
        "\n",
        "## Welcome! üëã\n",
        "\n",
        "In this notebook, you'll create your very first AI agent - a program that can think, use tools, and answer questions.\n",
        "\n",
        "## What is an Agent?\n",
        "\n",
        "An **agent** is an AI program that can:\n",
        "- Understand what you ask\n",
        "- Decide what tools it needs\n",
        "- Use those tools to find answers\n",
        "- Give you a helpful response\n",
        "\n",
        "Think of it like a smart assistant that knows when to search Google, when to do math, and when to just answer from what it knows.\n",
        "\n",
        "## What You'll Build\n",
        "\n",
        "By the end of this notebook, you'll have an agent that can:\n",
        "1. Search the web for current information\n",
        "2. Answer questions using its knowledge\n",
        "3. Run completely locally on your machine with Ollama\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "Make sure you have:\n",
        "- **Ollama installed**: Download from [ollama.com](https://ollama.com)\n",
        "- **Mistral-Nemo model**: Run `ollama pull mistral-nemo:12b` in your terminal. Select an LLM, SLM or RLM from this list [https://ollama.com/search](https://ollama.com/search)\n",
        "- **Tavily API key**: Get a free key from [tavily.com](https://tavily.com) for web search\n",
        "\n",
        "Let's get started!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 0: Setup"
      ],
      "metadata": {
        "id": "WFNTl0tUDA9R"
      },
      "id": "WFNTl0tUDA9R"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-ollama\n",
        "!pip install langchain-community"
      ],
      "metadata": {
        "id": "g5IQctsOF0Nb"
      },
      "id": "g5IQctsOF0Nb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install zstd"
      ],
      "metadata": {
        "id": "xy4XuzUnDDtO"
      },
      "id": "xy4XuzUnDDtO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update && sudo apt-get install -y zstd cuda-drivers\n",
        "!curl -fsSL https://ollama.ai/install.sh | sh\n",
        "import os\n",
        "os.environ.update({'LD_LIBRARY_PATH': '/usr/lib64-nvidia'})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmnudPQoDHSt",
        "outputId": "4b76daa4-9550-4bdc-a04d-d91efb75f57d"
      },
      "id": "bmnudPQoDHSt",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:2 https://cli.github.com/packages stable InRelease [3,917 B]\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [85.0 kB]\n",
            "Get:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:5 https://cli.github.com/packages stable/main amd64 Packages [356 B]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:7 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:9 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,751 kB]\n",
            "Get:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease [24.6 kB]\n",
            "Get:12 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [39.2 kB]\n",
            "Get:13 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy/main amd64 Packages [75.3 kB]\n",
            "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,904 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,728 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [70.9 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,731 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,300 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [6,511 kB]\n",
            "Get:21 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [62.6 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,613 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [4,063 kB]\n",
            "Fetched 37.4 MB in 4s (9,211 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "E: Unable to locate package cuda-drivers\n",
            ">>> Installing ollama to /usr/local\n",
            ">>> Downloading ollama-linux-amd64.tar.zst\n",
            "######################################################################## 100.0%\n",
            ">>> Creating ollama user...\n",
            ">>> Adding ollama user to video group...\n",
            ">>> Adding current user to ollama group...\n",
            ">>> Creating ollama systemd service...\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m systemd is not running\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m Unable to detect NVIDIA/AMD GPU. Install lspci or lshw to automatically detect and install GPU dependencies.\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup /usr/local/bin/ollama serve > ollama.log 2>&1 &"
      ],
      "metadata": {
        "id": "-ukjxEgdDMel"
      },
      "id": "-ukjxEgdDMel",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ollama pull mistral-nemo:12b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3ZGNf1gDM8U",
        "outputId": "0943b556-58f1-419e-d6f5-f3b8dad63c0a"
      },
      "id": "D3ZGNf1gDM8U",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ollama pull nomic-embed-text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8m600qEDPFG",
        "outputId": "02ed24c0-0c00-4ef8-83b6-e6816277b516"
      },
      "id": "O8m600qEDPFG",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b57a3c8d",
      "metadata": {
        "id": "b57a3c8d"
      },
      "source": [
        "## Step 1: Import What We Need\n",
        "\n",
        "\n",
        "\n",
        "Let's import the pieces we need to build our agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "59ee94bf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59ee94bf",
        "outputId": "3d8006c0-3ce2-41c0-96b1-44e3a297a315"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Ready to build an agent!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from langchain.agents import create_agent\n",
        "from langchain_ollama import ChatOllama\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "print(\"‚úì Ready to build an agent!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31292dc9",
      "metadata": {
        "id": "31292dc9"
      },
      "source": [
        "## Step 2: Give Your Agent a Tool\n",
        "\n",
        "Let's give our agent a **search tool** so it can look up current information on the web."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "736a6b59",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "736a6b59",
        "outputId": "7562040a-be9b-4f8b-e035-a2b118e12c5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Your agent has 1 tool available: search!\n"
          ]
        }
      ],
      "source": [
        "# Create a search tool that can look things up on the web\n",
        "search_tool = TavilySearchResults(max_results=3, tavily_api_key=userdata.get('TAVILY_API_KEY'))\n",
        "\n",
        "# Put it in a list (we can add more tools later)\n",
        "tools = [search_tool]\n",
        "\n",
        "print(f\"‚úì Your agent has {len(tools)} tool available: search!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "632912ec",
      "metadata": {
        "id": "632912ec"
      },
      "source": [
        "## Step 3: Create Your Agent with Ollama\n",
        "\n",
        "Now for the magic! Let's create an agent that runs locally using Ollama."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "dc082813",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dc082813",
        "outputId": "2dda36c9-85dd-4691-d864-a44c58c5ade3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Your agent is ready!\n",
            "  Running locally with Ollama!\n",
            "  It can think, search, and answer questions.\n"
          ]
        }
      ],
      "source": [
        "# Create a local model with Ollama\n",
        "model = ChatOllama(\n",
        "    model=\"mistral-nemo:12b\",\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "# Create an agent - it's this simple!\n",
        "agent = create_agent(\n",
        "    model=model,\n",
        "    tools=tools,\n",
        "    system_prompt=\"You are a helpful assistant. Use the search tool when you need current information.\"\n",
        ")\n",
        "\n",
        "print(\"‚úì Your agent is ready!\")\n",
        "print(\"  Running locally with Ollama!\")\n",
        "print(\"  It can think, search, and answer questions.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2487f47",
      "metadata": {
        "id": "c2487f47"
      },
      "source": [
        "## Step 4: Ask Your Agent a Question\n",
        "\n",
        "Let's try it out! We'll ask a question that needs current information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "f98cebeb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f98cebeb",
        "outputId": "0778991e-8e0a-4d47-a8e0-5a8ff772f936"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are the latest developments in AI in 2026?\n",
            "\n",
            "‚öôÔ∏è  Thinking and searching...\n",
            "\n",
            "Answer:\n",
            "Here are some of the latest developments in AI as predicted for 2026:\n",
            "\n",
            "1. **Open Source Competition**: Chinese AI firms like Zhipu and Moonshot are following DeepSeek's lead to open-source their models, pushing American firms to do the same. Alibaba's Qwen family has become an open-source powerhouse with its wide range of model sizes and specialized versions.\n",
            "\n",
            "2. **AI-driven Innovation**:\n",
            "   - Google DeepMind used AlphaEvolve to improve data center management and TPU chip efficiency.\n",
            "   - Open-source versions of AlphaEvolve have been released, including OpenEvolve by Asankhaya Sharma and SinkaEvolve by Sakana AI.\n",
            "   - A team of US and Chinese researchers revealed AlphaResearch, claiming it improves on one of AlphaEvolve's math solutions.\n",
            "\n",
            "3. **Hybrid Computing**: The rise of hybrid computing, where quantum works alongside AI and supercomputers, is expected to drive greater accuracy in modeling molecules and materials. Advances in logical qubits are making this possible.\n",
            "\n",
            "4. **AI in Scientific Research**: AI will become more central to the research process, generating hypotheses, using tools for scientific experiments, and collaborating with both human and AI colleagues in physics, chemistry, and biology.\n",
            "\n",
            "5. **Repository Intelligence**: The explosion of software development on platforms like GitHub is expected to bring about \"repository intelligence\" ‚Äì AI that understands not just lines of code but the relationships and history behind them.\n",
            "\n",
            "6. **Predictions from IBM Experts**: IBM's report predicts trends in AI, security, quantum computing, and other tech fields based on interviews with several experts across these areas.\n"
          ]
        }
      ],
      "source": [
        "# Ask a question\n",
        "query = \"What are the latest developments in AI in 2026?\"\n",
        "\n",
        "print(f\"Question: {query}\\n\")\n",
        "print(\"‚öôÔ∏è  Thinking and searching...\\n\")\n",
        "\n",
        "# Get the answer\n",
        "result = agent.invoke({\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": query}]\n",
        "})\n",
        "\n",
        "# Show the response\n",
        "print(\"Answer:\")\n",
        "print(result[\"messages\"][-1].content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6576acbe",
      "metadata": {
        "id": "6576acbe"
      },
      "source": [
        "## Step 5: Ask Without Needing Search\n",
        "\n",
        "The agent is smart enough to know when it doesn't need to search!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "996ac734",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "996ac734",
        "outputId": "6aeb0edd-3e18-420f-a06d-0e8124590969"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is 25 times 4?\n",
            "Answer: The result of 25 multiplied by 4 is 100.\n",
            "\n",
            "‚úì The agent answered directly without searching!\n"
          ]
        }
      ],
      "source": [
        "# A simple math question\n",
        "simple_query = \"What is 25 times 4?\"\n",
        "\n",
        "result = agent.invoke({\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": simple_query}]\n",
        "})\n",
        "\n",
        "print(f\"Question: {simple_query}\")\n",
        "print(f\"Answer: {result['messages'][-1].content}\")\n",
        "print(\"\\n‚úì The agent answered directly without searching!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "535e09a2",
      "metadata": {
        "id": "535e09a2"
      },
      "source": [
        "## üéâ Congratulations!\n",
        "\n",
        "You just built your first AI agent! Here's what you learned:\n",
        "\n",
        "### What You Did\n",
        "‚úÖ Created an AI agent with `create_agent()`  \n",
        "‚úÖ Gave it a tool to search the web  \n",
        "‚úÖ Asked questions and got intelligent answers  \n",
        "‚úÖ Saw how the agent decides when to use tools  \n",
        "‚úÖ Had a conversation with memory\n",
        "\n",
        "### What's Happening Behind the Scenes?\n",
        "When you ask a question, the agent:\n",
        "1. **Thinks**: \"Do I know this, or do I need to search?\"\n",
        "2. **Decides**: Uses tools if needed, or answers directly\n",
        "3. **Responds**: Gives you a helpful answer\n",
        "4. **Remembers**: Keeps track of the conversation\n",
        "\n",
        "### Next Steps\n",
        "In the next notebooks, you'll learn:\n",
        "- How agents work under the hood (state graphs)\n",
        "- How to give agents more tools\n",
        "- How to create multi-agent systems"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Try It Yourself!\n",
        "Experiment with different questions:\n",
        "- \"What's the weather in Tokyo today?\" (needs search)\n",
        "- \"What is 15% of 200?\" (can answer directly)\n",
        "- \"Tell me about AI\" then \"What are some examples?\" (uses memory)"
      ],
      "metadata": {
        "id": "BAPu8peJiYge"
      },
      "id": "BAPu8peJiYge"
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What's the weather in New Delhi today?\"\n",
        "\n",
        "print(f\"Question: {query}\\n\")\n",
        "print(\"‚öôÔ∏è  Thinking and searching...\\n\")\n",
        "\n",
        "# Get the answer\n",
        "result = agent.invoke({\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": query}]\n",
        "})\n",
        "\n",
        "# Show the response\n",
        "print(\"Answer:\")\n",
        "print(result[\"messages\"][-1].content)"
      ],
      "metadata": {
        "id": "SwX02eB2gcQY",
        "outputId": "e4b722c7-e6d9-477e-cb78-b1e726c371ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "SwX02eB2gcQY",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What's the weather in New Delhi today?\n",
            "\n",
            "‚öôÔ∏è  Thinking and searching...\n",
            "\n",
            "Answer:\n",
            "Here's the weather forecast for New Delhi today:\n",
            "\n",
            "- **Temperature**: High of 25¬∞C and low of 13¬∞C\n",
            "- **Weather**: Partly cloudy with a chance of patchy light rain and thunder\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "simple_query = \"What is 15% of 200?\"\n",
        "\n",
        "result = agent.invoke({\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": simple_query}]\n",
        "})\n",
        "\n",
        "print(f\"Question: {simple_query}\")\n",
        "print(f\"Answer: {result['messages'][-1].content}\")\n",
        "print(\"\\n‚úì The agent answered directly without searching!\")"
      ],
      "metadata": {
        "id": "xQjzomS1hH4a",
        "outputId": "f2379c12-490b-4b03-cd6a-f550d26e1e5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "xQjzomS1hH4a",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is 15% of 200?\n",
            "Answer: To find 15% of 200, you can follow these steps:\n",
            "\n",
            "1. Convert the percentage to a decimal by dividing by 100:\n",
            "   \\[\n",
            "   15\\% = \\frac{15}{100} = 0.15\n",
            "   \\]\n",
            "\n",
            "2. Multiply the decimal by the number:\n",
            "   \\[\n",
            "   x = 200 \\times 0.15\n",
            "   \\]\n",
            "\n",
            "3. Calculate the product:\n",
            "   \\[\n",
            "   x = 30\n",
            "   \\]\n",
            "\n",
            "So, 15% of 200 is 30.\n",
            "\n",
            "Alternatively, you can use the relationship between percent, part, and whole to solve for the unknown number:\n",
            "\n",
            "1. Divide the percentage by 100:\n",
            "   \\[\n",
            "   \\frac{15}{100} = 0.15\n",
            "   \\]\n",
            "\n",
            "2. Multiply the result by the number you want to find the percentage of:\n",
            "   \\[\n",
            "   x = 200 \\times 0.15\n",
            "   \\]\n",
            "\n",
            "3. Calculate the product:\n",
            "   \\[\n",
            "   x = 30\n",
            "   \\]\n",
            "\n",
            "Hence, 15% of 200 is 30.\n",
            "\n",
            "Another method is to use keywords and multiplication:\n",
            "\n",
            "1. Identify the keyword \"of\" which suggests multiplication.\n",
            "2. Convert the percentage to a decimal:\n",
            "   \\[\n",
            "   15\\% = 0.15\n",
            "   \\]\n",
            "\n",
            "3. Multiply the number by the decimal:\n",
            "   \\[\n",
            "   x = 200 \\times 0.15\n",
            "   \\]\n",
            "\n",
            "4. Calculate the product:\n",
            "   \\[\n",
            "   x = 30\n",
            "   \\]\n",
            "\n",
            "So, 15% of 200 is indeed 30.\n",
            "\n",
            "Source: [What is 15% of 200?](https://www.ck12.org/flexi/cbse-math/percentage/what-is-15-of-200/)\n",
            "\n",
            "‚úì The agent answered directly without searching!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Tell me about AI?\"\n",
        "\n",
        "print(f\"Question: {query}\\n\")\n",
        "print(\"‚öôÔ∏è  Thinking and searching...\\n\")\n",
        "\n",
        "# Get the answer\n",
        "result = agent.invoke({\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": query}]\n",
        "})\n",
        "\n",
        "# Show the response\n",
        "print(\"Answer:\")\n",
        "print(result[\"messages\"][-1].content)"
      ],
      "metadata": {
        "id": "lovljmZ8hBb_",
        "outputId": "e15895e8-318a-4b21-bf29-6b030a988755",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "lovljmZ8hBb_",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: Tell me about AI?\n",
            "\n",
            "‚öôÔ∏è  Thinking and searching...\n",
            "\n",
            "Answer:\n",
            "Here's a summary of the key points about Artificial Intelligence (AI) from the provided sources:\n",
            "\n",
            "**Definition:**\n",
            "- AI is focused on creating smart machines that can perform tasks typically requiring human intelligence, such as learning, reasoning, problem-solving, perception, and decision-making.\n",
            "- Instead of relying on explicit instructions, AI systems learn patterns from vast amounts of data to make predictions or decisions.\n",
            "\n",
            "**Types of AI:**\n",
            "1. **Narrow or Weak AI:** Designed to perform a single task (e.g., facial recognition, internet searches).\n",
            "2. **General or Strong AI:** Understands and learns any intellectual task that a human can do.\n",
            "3. **Superintelligent AI:** Significantly surpasses human intelligence in reasoning, creativity, and emotional intelligence.\n",
            "\n",
            "**Applications of AI:**\n",
            "- Everyday use: Virtual assistants, personalized recommendations, spam filters, navigation apps.\n",
            "- Healthcare: Disease diagnosis, treatment plans, drug discovery.\n",
            "- Transportation: Autonomous vehicles, intelligent traffic management systems.\n",
            "- Business operations: Customer service chatbots, fraud detection, supply chain optimization, marketing personalization.\n",
            "\n",
            "**Concerns:**\n",
            "- Existential risk to humanity if AI surpasses human intelligence without proper controls or understanding.\n",
            "- Ethical considerations regarding job displacement due to automation, privacy concerns, and potential misuse of AI technologies.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What are some examples?\"\n",
        "\n",
        "print(f\"Question: {query}\\n\")\n",
        "print(\"‚öôÔ∏è  Thinking and searching...\\n\")\n",
        "\n",
        "# Get the answer\n",
        "result = agent.invoke({\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": query}]\n",
        "})\n",
        "\n",
        "# Show the response\n",
        "print(\"Answer:\")\n",
        "print(result[\"messages\"][-1].content)"
      ],
      "metadata": {
        "id": "1WCmfJB2hbZX",
        "outputId": "3fb465fa-192a-49ac-8faf-65ea98d71362",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "1WCmfJB2hbZX",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are some examples?\n",
            "\n",
            "‚öôÔ∏è  Thinking and searching...\n",
            "\n",
            "Answer:\n",
            "Here are some examples of current events from various sources:\n",
            "\n",
            "1. **The New York Times:**\n",
            "   - **Title:** Current Events - The New York Times\n",
            "   - **Content:**\n",
            "     - Students share their feelings about America following two fatal shootings involving federal agents.\n",
            "     - A series of trials will explore if social media companies should be held responsible for teens' mental health struggles.\n",
            "     - Harvard proposes curbing grade inflation by limiting the number of A grades professors can award. What do you think?\n",
            "   - **Link:** https://www.nytimes.com/spotlight/learning-current-events\n",
            "\n",
            "2. **CNN:**\n",
            "   - **Title:** Breaking News, Latest News and Videos\n",
            "   - **Content:**\n",
            "     - A total solar eclipse swept across North America on April 8, 2024.\n",
            "     - SpaceX's Crew-12 Dragon successfully docked at the International Space Station on February 14.\n",
            "     - Former US Secretary of State Hillary Clinton spoke to the BBC at the Munich Security Conference.\n",
            "   - **Link:** https://www.cnn.com/\n",
            "\n",
            "3. **Associated Press News:**\n",
            "   - **Title:** Associated Press News: Breaking News, Latest Headlines ...\n",
            "   - **Content:**\n",
            "     - Trump family business files for trademark rights on any airports using the president‚Äôs name.\n",
            "     - Federal judge rules Kilmar Abrego Garcia can‚Äôt be re-detained by immigration authorities.\n",
            "     - Shooting at Rhode Island youth hockey game leaves 3 dead and 3 wounded.\n",
            "     - Billionaire Les Wexner is set to be deposed in congressional probe of Epstein files.\n",
            "   - **Link:** https://apnews.com/\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "rag-with-haystack-ch2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}